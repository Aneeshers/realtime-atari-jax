{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149644b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path updated:\n",
      "sys.path includes: /home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax\n",
      "PYTHONPATH env var: /home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax:\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path for the current Python session\n",
    "new_path = \"/home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax\"\n",
    "\n",
    "# Add to sys.path if not already there\n",
    "if new_path not in sys.path:\n",
    "    sys.path.insert(0, new_path)\n",
    "\n",
    "# Also set PYTHONPATH for any subprocesses\n",
    "os.environ[\"PYTHONPATH\"] = f\"{new_path}:{os.environ.get('PYTHONPATH', '')}\"\n",
    "\n",
    "# Verify it worked\n",
    "print(\"Python path updated:\")\n",
    "print(f\"sys.path includes: {new_path}\")\n",
    "print(f\"PYTHONPATH env var: {os.environ['PYTHONPATH']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede5aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def get_sizes(state):\n",
    "    try:\n",
    "        size = len(state.current_player)\n",
    "        width = math.ceil(math.sqrt(size - 0.1))\n",
    "        if size - (width - 1) ** 2 >= width:\n",
    "            height = width\n",
    "        else:\n",
    "            height = width - 1\n",
    "    except TypeError:\n",
    "        size = 1\n",
    "        width = 1\n",
    "        height = 1\n",
    "    return size, width, height\n",
    "\n",
    "\n",
    "def get_cmap(n_channels):\n",
    "    # import seaborn as sns  # type: ignore\n",
    "    # return cmap = sns.color_palette(\"cubehelix\", n_channels)\n",
    "    assert n_channels in (4, 6, 7, 10)\n",
    "    if n_channels == 4:\n",
    "        return [(0.08605633600581405, 0.23824692404212, 0.30561236308077167), (0.32927729263408284, 0.4762845556584382, 0.1837155549758328), (0.8146245329198283, 0.49548316572322215, 0.5752525936416857), (0.7587183008012618, 0.7922069335474338, 0.9543861221913403)]\n",
    "    elif n_channels == 6:\n",
    "        return [(0.10231025194333628, 0.13952898866828906, 0.2560120319409181), (0.10594361078604106, 0.3809739011595331, 0.27015111282899046), (0.4106130272672762, 0.48044780541672255, 0.1891154277778484), (0.7829183382530567, 0.48158303462490826, 0.48672451968362596), (0.8046168329276406, 0.6365733569301846, 0.8796578402926125), (0.7775608374378459, 0.8840392521212448, 0.9452007992345052)]\n",
    "    elif n_channels == 7:\n",
    "        return [(0.10419418740482515, 0.11632019220053316, 0.2327552016195138), (0.08523511613408935, 0.32661779003565533, 0.2973201282529313), (0.26538761550634205, 0.4675654910052002, 0.1908220644759285), (0.6328422475018423, 0.4747981096220677, 0.29070209208025455), (0.8306875710682655, 0.5175161303658079, 0.6628221028832032), (0.7779565181455343, 0.7069421942599752, 0.9314406084043191), (0.7964528047840354, 0.908668973545918, 0.9398253500983916)]\n",
    "    elif n_channels == 10:\n",
    "        return [(0.09854228363950114, 0.07115215572295082, 0.16957891809124037), (0.09159726558869188, 0.20394337960213008, 0.29623965888210324), (0.09406611799930162, 0.3578871412608098, 0.2837709711722866), (0.23627685553553793, 0.46114369021199075, 0.19770731888985724), (0.49498740849493095, 0.4799034869159042, 0.21147789468974837), (0.7354526513473981, 0.4748861903571046, 0.40254094042448907), (0.8325928529853291, 0.5253446757844744, 0.6869376931865354), (0.7936920632275369, 0.6641337211433709, 0.9042311843062529), (0.7588424692372241, 0.8253990353420474, 0.9542699331220588), (0.8385645211683802, 0.9411869386771845, 0.9357655639413166)]\n",
    "\n",
    "\n",
    "# /home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax/pgx/minatar/utils.py\n",
    "\n",
    "def visualize_minatar(state, savefile=None, fmt=\"svg\", dpi=160):\n",
    "    # Modified from https://github.com/kenjyoung/MinAtar\n",
    "    try:\n",
    "        import matplotlib.colors as colors  # type: ignore\n",
    "        import matplotlib.pyplot as plt  # type: ignore\n",
    "    except ImportError:\n",
    "        sys.stderr.write(\"MinAtar environment requires matplotlib for visualization. Please install matplotlib.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    obs = state.observation\n",
    "    n_channels = obs.shape[-1]\n",
    "    cmap = get_cmap(n_channels)\n",
    "    cmap.insert(0, (0, 0, 0))\n",
    "    cmap = colors.ListedColormap(cmap)\n",
    "    bounds = [i for i in range(n_channels + 2)]\n",
    "    norm = colors.BoundaryNorm(bounds, n_channels + 1)\n",
    "    size, w, h = get_sizes(state)\n",
    "    fig, ax = plt.subplots(h, w)\n",
    "    n_channels = obs.shape[-1]\n",
    "    if size == 1:\n",
    "        numerical_state = (\n",
    "            jnp.amax(\n",
    "                obs * jnp.reshape(jnp.arange(n_channels) + 1, (1, 1, -1)), 2\n",
    "            )\n",
    "            + 0.5\n",
    "        )\n",
    "        ax.imshow(numerical_state, cmap=cmap, norm=norm, interpolation=\"none\")\n",
    "        ax.set_axis_off()\n",
    "    else:\n",
    "        for j in range(size):\n",
    "            numerical_state = (\n",
    "                jnp.amax(\n",
    "                    obs[j] * jnp.reshape(jnp.arange(n_channels) + 1, (1, 1, -1)),\n",
    "                    2,\n",
    "                )\n",
    "                + 0.5\n",
    "            )\n",
    "            if h == 1:\n",
    "                ax[j].imshow(numerical_state, cmap=cmap, norm=norm, interpolation=\"none\")\n",
    "                ax[j].set_axis_off()\n",
    "            else:\n",
    "                ax[j // w, j % w].imshow(numerical_state, cmap=cmap, norm=norm, interpolation=\"none\")\n",
    "                ax[j // w, j % w].set_axis_off()\n",
    "\n",
    "    if savefile is None:\n",
    "        # Return in-memory image\n",
    "        if fmt == \"svg\":\n",
    "            from io import StringIO\n",
    "            sio = StringIO()\n",
    "            plt.savefig(sio, format=\"svg\", bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "            return sio.getvalue()  # str (SVG markup)\n",
    "        else:\n",
    "            from io import BytesIO\n",
    "            bio = BytesIO()\n",
    "            plt.savefig(bio, format=fmt, bbox_inches=\"tight\", dpi=dpi)\n",
    "            plt.close(fig)\n",
    "            bio.seek(0)\n",
    "            return bio.getvalue()  # bytes (e.g., PNG)\n",
    "    else:\n",
    "        plt.savefig(savefile, format=fmt, bbox_inches=\"tight\", dpi=(None if fmt == \"svg\" else dpi))\n",
    "        plt.close(fig)\n",
    "        return savefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MinAtar/Freeway with JIT-compatible K-frame skipping.\n",
    "\n",
    "Changes vs. baseline:\n",
    "- Add `frame_skip: int = 2` to MinAtarFreeway.__init__.\n",
    "- Implement frame skipping inside `_step` via `jax.lax.fori_loop`.\n",
    "- Compute one sticky-processed effective action per external step and repeat it\n",
    "  for `frame_skip` internal steps, accumulating rewards. Each micro-step samples\n",
    "  new car speeds/directions (as in the original logic).\n",
    "\"\"\"\n",
    "\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import pgx.core as core\n",
    "from pgx._src.struct import dataclass\n",
    "from pgx._src.types import Array, PRNGKey\n",
    "\n",
    "player_speed = jnp.array(3, dtype=jnp.int32)\n",
    "time_limit = jnp.array(2500, dtype=jnp.int32)\n",
    "\n",
    "FALSE = jnp.bool_(False)\n",
    "TRUE = jnp.bool_(True)\n",
    "ZERO = jnp.array(0, dtype=jnp.int32)\n",
    "ONE = jnp.array(1, dtype=jnp.int32)\n",
    "NINE = jnp.array(9, dtype=jnp.int32)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State(core.State):\n",
    "    current_player: Array = jnp.int32(0)\n",
    "    observation: Array = jnp.zeros((10, 10, 7), dtype=jnp.bool_)\n",
    "    rewards: Array = jnp.zeros(1, dtype=jnp.float32)  # (1,)\n",
    "    terminated: Array = FALSE\n",
    "    truncated: Array = FALSE\n",
    "    legal_action_mask: Array = jnp.ones(3, dtype=jnp.bool_)\n",
    "    _step_count: Array = jnp.int32(0)\n",
    "    # --- MinAtar Freeway specific ---\n",
    "    _cars: Array = jnp.zeros((8, 4), dtype=jnp.int32)\n",
    "    _pos: Array = jnp.array(9, dtype=jnp.int32)\n",
    "    _move_timer: Array = jnp.array(player_speed, dtype=jnp.int32)\n",
    "    _terminate_timer: Array = jnp.array(time_limit, dtype=jnp.int32)\n",
    "    _terminal: Array = jnp.array(False, dtype=jnp.bool_)\n",
    "    _last_action: Array = jnp.array(0, dtype=jnp.int32)\n",
    "\n",
    "    @property\n",
    "    def env_id(self) -> core.EnvId:\n",
    "        return \"minatar-freeway\"\n",
    "\n",
    "    def to_svg(\n",
    "        self,\n",
    "        *,\n",
    "        color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n",
    "        scale: Optional[float] = None,\n",
    "    ) -> str:\n",
    "        del color_theme, scale\n",
    "        from .utils import visualize_minatar\n",
    "\n",
    "        return visualize_minatar(self)\n",
    "\n",
    "    def save_svg(\n",
    "        self,\n",
    "        filename,\n",
    "        *,\n",
    "        color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n",
    "        scale: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        from .utils import visualize_minatar\n",
    "\n",
    "        visualize_minatar(self, filename)\n",
    "\n",
    "\n",
    "class MinAtarFreeway(core.Env):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        use_minimal_action_set: bool = True,\n",
    "        sticky_action_prob: float = 0.1,\n",
    "        frame_skip: int = 2,  # NEW: K-frame skipping (default 2)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert frame_skip >= 1, \"frame_skip must be >= 1\"\n",
    "        self.use_minimal_action_set = use_minimal_action_set\n",
    "        self.sticky_action_prob: float = float(sticky_action_prob)\n",
    "        self.frame_skip: int = int(frame_skip)\n",
    "\n",
    "        self.minimal_action_set = jnp.int32([0, 2, 4])\n",
    "        self.legal_action_mask = jnp.ones(6, dtype=jnp.bool_)\n",
    "        if self.use_minimal_action_set:\n",
    "            self.legal_action_mask = jnp.ones(\n",
    "                self.minimal_action_set.shape[0], dtype=jnp.bool_\n",
    "            )\n",
    "\n",
    "    def step(\n",
    "        self, state: core.State, action: Array, key: Optional[Array] = None\n",
    "    ) -> core.State:\n",
    "        assert key is not None, (\n",
    "            \"v2.0.0 changes the signature of step. Please specify PRNGKey at the third argument:\\n\\n\"\n",
    "            \"  * <  v2.0.0: step(state, action)\\n\"\n",
    "            \"  * >= v2.0.0: step(state, action, key)\\n\\n\"\n",
    "            \"See v2.0.0 release note for more details:\\n\\n\"\n",
    "            \"  https://github.com/sotetsuk/pgx/releases/tag/v2.0.0\"\n",
    "        )\n",
    "        return super().step(state, action, key)\n",
    "\n",
    "    def _init(self, key: PRNGKey) -> State:\n",
    "        state = _init(rng=key)  # type: ignore\n",
    "        state = state.replace(legal_action_mask=self.legal_action_mask)  # type: ignore\n",
    "        return state  # type: ignore\n",
    "\n",
    "    def _step(self, state: core.State, action, key) -> State:\n",
    "        assert isinstance(state, State)\n",
    "        # Keep mask current\n",
    "        state = state.replace(legal_action_mask=self.legal_action_mask)  # type: ignore\n",
    "\n",
    "        # Map minimal action set if enabled\n",
    "        action = jax.lax.select(\n",
    "            jnp.bool_(self.use_minimal_action_set),\n",
    "            self.minimal_action_set[action],\n",
    "            action,\n",
    "        )\n",
    "        action = jnp.int32(action)\n",
    "\n",
    "        # Sticky override ONCE per external step; then repeat effective action\n",
    "        key_sticky, key_loop = jax.random.split(key, 2)\n",
    "        effective_action = jax.lax.cond(\n",
    "            jax.random.uniform(key_sticky) < self.sticky_action_prob,\n",
    "            lambda: state._last_action,\n",
    "            lambda: action,\n",
    "        )\n",
    "        effective_action = jnp.int32(effective_action)\n",
    "\n",
    "        # fori_loop carry: (State, total_reward(float32), done(bool), rng)\n",
    "        def body_fn(i, carry):\n",
    "            s, rsum, done, rng = carry\n",
    "\n",
    "            def do_step(args):\n",
    "                s_inner, rsum_inner, _done_inner, rng_inner = args\n",
    "                rng_inner, sub = jax.random.split(rng_inner)\n",
    "                speeds, directions = _random_speed_directions(sub)\n",
    "                s_next = _step_det(s_inner, effective_action, speeds=speeds, directions=directions)\n",
    "                rsum_next = rsum_inner + s_next.rewards[0]\n",
    "                done_next = s_next.terminated\n",
    "                return (s_next, rsum_next, done_next, rng_inner)\n",
    "\n",
    "            return jax.lax.cond(done, lambda x: x, do_step, (s, rsum, done, rng))\n",
    "\n",
    "        r0 = jnp.array(0.0, dtype=jnp.float32)\n",
    "        d0 = FALSE\n",
    "        state, total_r, _, _ = jax.lax.fori_loop(\n",
    "            0, int(self.frame_skip), body_fn, (state, r0, d0, key_loop)\n",
    "        )\n",
    "\n",
    "        # Overwrite reward with accumulated total for this external step\n",
    "        state = state.replace(rewards=total_r[jnp.newaxis])  # type: ignore\n",
    "        return state  # type: ignore\n",
    "\n",
    "    def _observe(self, state: core.State, player_id: Array) -> Array:\n",
    "        assert isinstance(state, State)\n",
    "        return _observe(state)\n",
    "\n",
    "    @property\n",
    "    def id(self) -> core.EnvId:\n",
    "        return \"minatar-freeway\"\n",
    "\n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        return \"v1\"\n",
    "\n",
    "    @property\n",
    "    def num_players(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "def _step(\n",
    "    state: State,\n",
    "    action: Array,\n",
    "    key,\n",
    "    sticky_action_prob,\n",
    "):\n",
    "    # (Kept for API completeness; not used when class-level frame_skip is active)\n",
    "    action = jnp.int32(action)\n",
    "    key0, key1 = jax.random.split(key, 2)\n",
    "    action = jax.lax.cond(\n",
    "        jax.random.uniform(key0) < sticky_action_prob,\n",
    "        lambda: state._last_action,\n",
    "        lambda: action,\n",
    "    )\n",
    "    speeds, directions = _random_speed_directions(key1)\n",
    "    return _step_det(state, action, speeds=speeds, directions=directions)\n",
    "\n",
    "\n",
    "def _init(rng: Array) -> State:\n",
    "    speeds, directions = _random_speed_directions(rng)\n",
    "    return _init_det(speeds=speeds, directions=directions)\n",
    "\n",
    "\n",
    "def _step_det(\n",
    "    state: State,\n",
    "    action: Array,\n",
    "    speeds: Array,\n",
    "    directions: Array,\n",
    "):\n",
    "    cars = state._cars\n",
    "    pos = state._pos\n",
    "    move_timer = state._move_timer\n",
    "    terminate_timer = state._terminate_timer\n",
    "    terminal = state._terminal\n",
    "    last_action = action\n",
    "\n",
    "    r = jnp.array(0, dtype=jnp.float32)\n",
    "\n",
    "    move_timer, pos = jax.lax.cond(\n",
    "        (action == 2) & (move_timer == 0),\n",
    "        lambda: (player_speed, jax.lax.max(ZERO, pos - ONE)),\n",
    "        lambda: (move_timer, pos),\n",
    "    )\n",
    "    move_timer, pos = jax.lax.cond(\n",
    "        (action == 4) & (move_timer == 0),\n",
    "        lambda: (player_speed, jax.lax.min(NINE, pos + ONE)),\n",
    "        lambda: (move_timer, pos),\n",
    "    )\n",
    "\n",
    "    # Win condition\n",
    "    cars, r, pos = jax.lax.cond(\n",
    "        pos == 0,\n",
    "        lambda: (\n",
    "            _randomize_cars(speeds, directions, cars, initialize=False),\n",
    "            r + 1,\n",
    "            NINE,\n",
    "        ),\n",
    "        lambda: (cars, r, pos),\n",
    "    )\n",
    "\n",
    "    pos, cars = _update_cars(pos, cars)\n",
    "\n",
    "    # Update various timers\n",
    "    move_timer = jax.lax.cond(\n",
    "        move_timer > 0, lambda: move_timer - 1, lambda: move_timer\n",
    "    )\n",
    "    terminate_timer -= ONE\n",
    "    terminal = terminate_timer < 0\n",
    "\n",
    "    next_state = state.replace(  # type: ignore\n",
    "        _cars=cars,\n",
    "        _pos=pos,\n",
    "        _move_timer=move_timer,\n",
    "        _terminate_timer=terminate_timer,\n",
    "        _terminal=terminal,\n",
    "        _last_action=last_action,\n",
    "        rewards=r[jnp.newaxis],\n",
    "        terminated=terminal,\n",
    "    )\n",
    "\n",
    "    return next_state\n",
    "\n",
    "\n",
    "def _update_cars(pos, cars):\n",
    "    def _update_stopped_car(pos, car):\n",
    "        car = car.at[2].set(jax.lax.abs(car[3]))\n",
    "        car = jax.lax.cond(\n",
    "            car[3] > 0, lambda: car.at[0].add(1), lambda: car.at[0].add(-1)\n",
    "        )\n",
    "        car = jax.lax.cond(car[0] < 0, lambda: car.at[0].set(9), lambda: car)\n",
    "        car = jax.lax.cond(car[0] > 9, lambda: car.at[0].set(0), lambda: car)\n",
    "        pos = jax.lax.cond(\n",
    "            (car[0] == 4) & (car[1] == pos), lambda: NINE, lambda: pos\n",
    "        )\n",
    "        return pos, car\n",
    "\n",
    "    def _update_car(pos, car):\n",
    "        pos = jax.lax.cond(\n",
    "            (car[0] == 4) & (car[1] == pos), lambda: NINE, lambda: pos\n",
    "        )\n",
    "        pos, car = jax.lax.cond(\n",
    "            car[2] == 0,\n",
    "            lambda: _update_stopped_car(pos, car),\n",
    "            lambda: (pos, car.at[2].add(-1)),\n",
    "        )\n",
    "        return pos, car\n",
    "\n",
    "    pos, cars = jax.lax.scan(_update_car, pos, cars)\n",
    "\n",
    "    return pos, cars\n",
    "\n",
    "\n",
    "def _init_det(speeds: Array, directions: Array) -> State:\n",
    "    cars = _randomize_cars(speeds, directions, initialize=True)\n",
    "    return State(_cars=cars)  # type: ignore\n",
    "\n",
    "\n",
    "def _randomize_cars(\n",
    "    speeds: Array,\n",
    "    directions: Array,\n",
    "    cars: Array = jnp.zeros((8, 4), dtype=int),\n",
    "    initialize: bool = False,\n",
    ") -> Array:\n",
    "    speeds *= directions\n",
    "\n",
    "    def _init(_cars):\n",
    "        _cars = _cars.at[:, 1].set(jnp.arange(1, 9))\n",
    "        _cars = _cars.at[:, 2].set(jax.lax.abs(speeds))\n",
    "        _cars = _cars.at[:, 3].set(speeds)\n",
    "        return _cars\n",
    "\n",
    "    def _update(_cars):\n",
    "        _cars = _cars.at[:, 2].set(abs(speeds))\n",
    "        _cars = _cars.at[:, 3].set(speeds)\n",
    "        return _cars\n",
    "\n",
    "    return jax.lax.cond(initialize, _init, _update, cars)\n",
    "\n",
    "\n",
    "def _random_speed_directions(rng):\n",
    "    rng1, rng2 = jax.random.split(rng, 2)\n",
    "    speeds = jax.random.randint(rng1, [8], 1, 6, dtype=jnp.int32)\n",
    "    directions = jax.random.choice(\n",
    "        rng2, jnp.array([-1, 1], dtype=jnp.int32), [8]\n",
    "    )\n",
    "    return speeds, directions\n",
    "\n",
    "\n",
    "def _observe(state: State) -> Array:\n",
    "    obs = jnp.zeros((10, 10, 7), dtype=jnp.bool_)\n",
    "    obs = obs.at[state._pos, 4, 0].set(TRUE)\n",
    "\n",
    "    def _update_obs(i, _obs):\n",
    "        car = state._cars[i]\n",
    "        _obs = _obs.at[car[1], car[0], 1].set(TRUE)\n",
    "        back_x = jax.lax.cond(\n",
    "            car[3] > 0, lambda: car[0] - 1, lambda: car[0] + 1\n",
    "        )\n",
    "        back_x = jax.lax.cond(back_x < 0, lambda: NINE, lambda: back_x)\n",
    "        back_x = jax.lax.cond(back_x > 9, lambda: ZERO, lambda: back_x)\n",
    "        trail = jax.lax.abs(car[3]) + 1\n",
    "        _obs = _obs.at[car[1], back_x, trail].set(TRUE)\n",
    "        return _obs\n",
    "\n",
    "    obs = jax.lax.fori_loop(0, 8, _update_obs, obs)\n",
    "    return obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ba5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MinAtar/Breakout with JIT-compatible K-frame skipping.\n",
    "\n",
    "Changes vs. baseline:\n",
    "- Add `frame_skip: int = 2` to MinAtarBreakout.__init__.\n",
    "- Implement frame skipping inside `_step` via `jax.lax.fori_loop`.\n",
    "- Compute a single effective action (after sticky override) and repeat it\n",
    "  for `frame_skip` internal steps, accumulating rewards. Observation comes\n",
    "  from the final internal step, and `terminated` reflects any terminal reached\n",
    "  during the repeated steps.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import pgx.core as core\n",
    "from pgx._src.struct import dataclass\n",
    "from pgx._src.types import Array, PRNGKey\n",
    "\n",
    "FALSE = jnp.bool_(False)\n",
    "TRUE = jnp.bool_(True)\n",
    "ZERO = jnp.array(0, dtype=jnp.int32)\n",
    "ONE = jnp.array(1, dtype=jnp.int32)\n",
    "TWO = jnp.array(2, dtype=jnp.int32)\n",
    "THREE = jnp.array(3, dtype=jnp.int32)\n",
    "FOUR = jnp.array(4, dtype=jnp.int32)\n",
    "NINE = jnp.array(9, dtype=jnp.int32)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State(core.State):\n",
    "    current_player: Array = jnp.int32(0)\n",
    "    observation: Array = jnp.zeros((10, 10, 4), dtype=jnp.bool_)\n",
    "    rewards: Array = jnp.zeros(1, dtype=jnp.float32)  # (1,)\n",
    "    terminated: Array = FALSE\n",
    "    truncated: Array = FALSE\n",
    "    legal_action_mask: Array = jnp.ones(3, dtype=jnp.bool_)\n",
    "    _step_count: Array = jnp.int32(0)\n",
    "    # --- MinAtar Breakout specific ---\n",
    "    _ball_y: Array = THREE\n",
    "    _ball_x: Array = ZERO\n",
    "    _ball_dir: Array = TWO\n",
    "    _pos: Array = FOUR\n",
    "    _brick_map: Array = (\n",
    "        jnp.zeros((10, 10), dtype=jnp.bool_).at[1:4, :].set(True)\n",
    "    )\n",
    "    _strike: Array = jnp.array(False, dtype=jnp.bool_)\n",
    "    _last_x: Array = ZERO\n",
    "    _last_y: Array = THREE\n",
    "    _terminal: Array = jnp.array(False, dtype=jnp.bool_)\n",
    "    _last_action: Array = ZERO\n",
    "\n",
    "    @property\n",
    "    def env_id(self) -> core.EnvId:\n",
    "        return \"minatar-breakout\"\n",
    "\n",
    "    def to_svg(\n",
    "        self,\n",
    "        *,\n",
    "        color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n",
    "        scale: Optional[float] = None,\n",
    "    ) -> str:\n",
    "        del color_theme, scale\n",
    "        from .utils import visualize_minatar\n",
    "\n",
    "        return visualize_minatar(self)\n",
    "\n",
    "    def save_svg(\n",
    "        self,\n",
    "        filename,\n",
    "        *,\n",
    "        color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n",
    "        scale: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        from .utils import visualize_minatar\n",
    "\n",
    "        visualize_minatar(self, filename)\n",
    "\n",
    "\n",
    "class MinAtarBreakout(core.Env):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        use_minimal_action_set: bool = True,\n",
    "        sticky_action_prob: float = 0.1,\n",
    "        frame_skip: int = 2,  # NEW: K-frame skipping (default 2)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert frame_skip >= 1, \"frame_skip must be >= 1\"\n",
    "        self.use_minimal_action_set = use_minimal_action_set\n",
    "        self.sticky_action_prob: float = float(sticky_action_prob)\n",
    "        self.frame_skip: int = int(frame_skip)\n",
    "\n",
    "        # Minimal action set mapping (NOOP/LEFT/RIGHT for Breakout)\n",
    "        self.minimal_action_set = jnp.int32([0, 1, 3])\n",
    "\n",
    "        # Legal mask is either 6 (full) or 3 (minimal)\n",
    "        self.legal_action_mask = jnp.ones(6, dtype=jnp.bool_)\n",
    "        if self.use_minimal_action_set:\n",
    "            self.legal_action_mask = jnp.ones(\n",
    "                self.minimal_action_set.shape[0], dtype=jnp.bool_\n",
    "            )\n",
    "\n",
    "    def step(\n",
    "        self, state: core.State, action: Array, key: Optional[Array] = None\n",
    "    ) -> core.State:\n",
    "        assert key is not None, (\n",
    "            \"v2.0.0 changes the signature of step. Please specify PRNGKey at the third argument:\\n\\n\"\n",
    "            \"  * <  v2.0.0: step(state, action)\\n\"\n",
    "            \"  * >= v2.0.0: step(state, action, key)\\n\\n\"\n",
    "            \"See v2.0.0 release note for more details:\\n\\n\"\n",
    "            \"  https://github.com/sotetsuk/pgx/releases/tag/v2.0.0\"\n",
    "        )\n",
    "        return super().step(state, action, key)\n",
    "\n",
    "    def _init(self, key: PRNGKey) -> State:\n",
    "        state = _init(rng=key)  # type: ignore\n",
    "        state = state.replace(legal_action_mask=self.legal_action_mask)  # type: ignore\n",
    "        return state  # type: ignore\n",
    "\n",
    "    def _step(self, state: core.State, action, key) -> State:\n",
    "        \"\"\"One external env step = repeat the (sticky-processed) action for `frame_skip` internal steps.\"\"\"\n",
    "        # Ensure the state carries the current legal mask\n",
    "        state = state.replace(legal_action_mask=self.legal_action_mask)  # type: ignore\n",
    "\n",
    "        # Minimal action set mapping (JAX-friendly select)\n",
    "        action = jax.lax.select(\n",
    "            jnp.bool_(self.use_minimal_action_set),\n",
    "            self.minimal_action_set[action],\n",
    "            action,\n",
    "        )\n",
    "\n",
    "        # Compute effective action once (sticky override) for this macro-step\n",
    "        # Then repeat that effective action for `frame_skip` internal steps.\n",
    "        effective_action = jax.lax.cond(\n",
    "            jax.random.uniform(key) < self.sticky_action_prob,\n",
    "            lambda: jnp.int32(state._last_action),\n",
    "            lambda: jnp.int32(action),\n",
    "        )\n",
    "\n",
    "        # fori_loop carry: (State, total_reward(float32), done(bool))\n",
    "        def body_fn(i, carry):\n",
    "            s, rsum, done = carry\n",
    "\n",
    "            def do_step(args):\n",
    "                s_inner, rsum_inner, _ = args\n",
    "                s_next = _step_det(s_inner, effective_action)\n",
    "                rsum_next = rsum_inner + s_next.rewards[0]\n",
    "                done_next = s_next.terminated\n",
    "                return (s_next, rsum_next, done_next)\n",
    "\n",
    "            # If already done, keep state as-is (no-op), preserving JIT compatibility\n",
    "            return jax.lax.cond(done, lambda x: x, do_step, (s, rsum, done))\n",
    "\n",
    "        r0 = jnp.array(0.0, dtype=jnp.float32)\n",
    "        d0 = FALSE\n",
    "        state, total_r, _ = jax.lax.fori_loop(0, int(self.frame_skip), body_fn, (state, r0, d0))\n",
    "\n",
    "        # Overwrite rewards with the accumulated total for this external step\n",
    "        state = state.replace(rewards=total_r[jnp.newaxis])  # type: ignore\n",
    "        return state  # type: ignore\n",
    "\n",
    "    def _observe(self, state: core.State, player_id: Array) -> Array:\n",
    "        assert isinstance(state, State)\n",
    "        return _observe(state)\n",
    "\n",
    "    @property\n",
    "    def id(self) -> core.EnvId:\n",
    "        return \"minatar-breakout\"\n",
    "\n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        return \"v1\"\n",
    "\n",
    "    @property\n",
    "    def num_players(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "def _step_det(state: State, action: Array):\n",
    "    ball_y = state._ball_y\n",
    "    ball_x = state._ball_x\n",
    "    ball_dir = state._ball_dir\n",
    "    pos = state._pos\n",
    "    brick_map = state._brick_map\n",
    "    strike = state._strike\n",
    "    terminal = state._terminal\n",
    "\n",
    "    r = jnp.array(0, dtype=jnp.float32)\n",
    "\n",
    "    pos = _apply_action(pos, action)\n",
    "\n",
    "    # Update ball position\n",
    "    last_x = ball_x\n",
    "    last_y = ball_y\n",
    "    new_x, new_y = _update_ball_pos(ball_x, ball_y, ball_dir)\n",
    "\n",
    "    new_x, ball_dir = jax.lax.cond(\n",
    "        (new_x < 0) | (new_x > 9),\n",
    "        lambda: _update_ball_pos_x(new_x, ball_dir),\n",
    "        lambda: (new_x, ball_dir),\n",
    "    )\n",
    "\n",
    "    is_new_y_negative = new_y < 0\n",
    "    is_strike = brick_map[new_y, new_x] == 1\n",
    "    is_bottom = new_y == 9\n",
    "    new_y, ball_dir = jax.lax.cond(\n",
    "        is_new_y_negative,\n",
    "        lambda: _update_ball_pos_y(ball_dir),\n",
    "        lambda: (new_y, ball_dir),\n",
    "    )\n",
    "    strike_toggle = ~is_new_y_negative & is_strike\n",
    "    r, strike, brick_map, new_y, ball_dir = jax.lax.cond(\n",
    "        ~is_new_y_negative & is_strike & ~strike,\n",
    "        lambda: _update_by_strike(\n",
    "            r, brick_map, new_x, new_y, last_y, ball_dir, strike\n",
    "        ),\n",
    "        lambda: (r, strike, brick_map, new_y, ball_dir),\n",
    "    )\n",
    "    brick_map, new_y, ball_dir, terminal = jax.lax.cond(\n",
    "        ~is_new_y_negative & ~is_strike & is_bottom,\n",
    "        lambda: _update_by_bottom(\n",
    "            brick_map, ball_x, new_x, new_y, pos, ball_dir, last_y, terminal\n",
    "        ),\n",
    "        lambda: (brick_map, new_y, ball_dir, terminal),\n",
    "    )\n",
    "\n",
    "    strike = jax.lax.cond(\n",
    "        ~strike_toggle, lambda: jnp.zeros_like(strike), lambda: strike\n",
    "    )\n",
    "\n",
    "    state = state.replace(  # type: ignore\n",
    "        _ball_y=new_y,\n",
    "        _ball_x=new_x,\n",
    "        _ball_dir=ball_dir,\n",
    "        _pos=pos,\n",
    "        _brick_map=brick_map,\n",
    "        _strike=strike,\n",
    "        _last_x=last_x,\n",
    "        _last_y=last_y,\n",
    "        _terminal=terminal,\n",
    "        _last_action=action,\n",
    "        rewards=r[jnp.newaxis],\n",
    "        terminated=terminal,\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "def _init(rng: Array) -> State:\n",
    "    ball_start = jax.random.choice(rng, 2)\n",
    "    return _init_det(ball_start=ball_start)\n",
    "\n",
    "\n",
    "def _apply_action(pos, action):\n",
    "    pos = jax.lax.cond(\n",
    "        action == 1, lambda: jax.lax.max(ZERO, pos - ONE), lambda: pos\n",
    "    )\n",
    "    pos = jax.lax.cond(\n",
    "        action == 3, lambda: jax.lax.min(NINE, pos + ONE), lambda: pos\n",
    "    )\n",
    "    return pos\n",
    "\n",
    "\n",
    "def _update_ball_pos(ball_x, ball_y, ball_dir):\n",
    "    return jax.lax.switch(\n",
    "        ball_dir,\n",
    "        [\n",
    "            lambda: (ball_x - ONE, ball_y - ONE),\n",
    "            lambda: (ball_x + ONE, ball_y - ONE),\n",
    "            lambda: (ball_x + ONE, ball_y + ONE),\n",
    "            lambda: (ball_x - ONE, ball_y + ONE),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def _update_ball_pos_x(new_x, ball_dir):\n",
    "    new_x = jax.lax.max(ZERO, new_x)\n",
    "    new_x = jax.lax.min(NINE, new_x)\n",
    "    ball_dir = jnp.array([1, 0, 3, 2], dtype=jnp.int32)[ball_dir]\n",
    "    return new_x, ball_dir\n",
    "\n",
    "\n",
    "def _update_ball_pos_y(ball_dir):\n",
    "    ball_dir = jnp.array([3, 2, 1, 0], dtype=jnp.int32)[ball_dir]\n",
    "    return ZERO, ball_dir\n",
    "\n",
    "\n",
    "def _update_by_strike(r, brick_map, new_x, new_y, last_y, ball_dir, strike):\n",
    "    brick_map = brick_map.at[new_y, new_x].set(False)\n",
    "    new_y = last_y\n",
    "    ball_dir = jnp.array([3, 2, 1, 0], dtype=jnp.int32)[ball_dir]\n",
    "    return r + 1, jnp.ones_like(strike), brick_map, new_y, ball_dir\n",
    "\n",
    "\n",
    "def _update_by_bottom(\n",
    "    brick_map, ball_x, new_x, new_y, pos, ball_dir, last_y, terminal\n",
    "):\n",
    "    brick_map = jax.lax.cond(\n",
    "        brick_map.sum() == 0,\n",
    "        lambda: brick_map.at[1:4, :].set(True),\n",
    "        lambda: brick_map,\n",
    "    )\n",
    "    new_y, ball_dir, terminal = jax.lax.cond(\n",
    "        ball_x == pos,\n",
    "        lambda: (\n",
    "            last_y,\n",
    "            jnp.array([3, 2, 1, 0], dtype=jnp.int32)[ball_dir],\n",
    "            terminal,\n",
    "        ),\n",
    "        lambda: jax.lax.cond(\n",
    "            new_x == pos,\n",
    "            lambda: (\n",
    "                last_y,\n",
    "                jnp.array([2, 3, 0, 1], dtype=jnp.int32)[ball_dir],\n",
    "                terminal,\n",
    "            ),\n",
    "            lambda: (new_y, ball_dir, jnp.array(True, dtype=jnp.bool_)),\n",
    "        ),\n",
    "    )\n",
    "    return brick_map, new_y, ball_dir, terminal\n",
    "\n",
    "\n",
    "def _init_det(ball_start: Array) -> State:\n",
    "    ball_x, ball_dir = jax.lax.switch(\n",
    "        ball_start,\n",
    "        [lambda: (ZERO, TWO), lambda: (NINE, THREE)],\n",
    "    )\n",
    "    last_x = ball_x\n",
    "    return State(\n",
    "        _ball_x=ball_x, _ball_dir=ball_dir, _last_x=last_x\n",
    "    )  # type: ignore\n",
    "\n",
    "\n",
    "def _observe(state: State) -> Array:\n",
    "    obs = jnp.zeros((10, 10, 4), dtype=jnp.bool_)\n",
    "    obs = obs.at[state._ball_y, state._ball_x, 1].set(True)\n",
    "    obs = obs.at[9, state._pos, 0].set(True)\n",
    "    obs = obs.at[state._last_y, state._last_x, 2].set(True)\n",
    "    obs = obs.at[:, :, 3].set(state._brick_map)\n",
    "    return obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f6fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: env_name='minatar-breakout' seed=0 lr=0.0003 num_envs=4096 num_eval_envs=100 num_steps=128 total_timesteps=100000000 frame_skip=6 update_epochs=3 minibatch_size=4096 gamma=0.99 gae_lambda=0.95 clip_eps=0.2 ent_coef=0.01 vf_coef=0.5 max_grad_norm=0.5 wandb_project='pgx-minatar-ppo' save_model=True\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "from pydantic import BaseModel\n",
    "import pgx\n",
    "class PPOConfig(BaseModel):\n",
    "    env_name: Literal[\n",
    "        \"minatar-breakout\",\n",
    "        \"minatar-freeway\",\n",
    "        \"minatar-space_invaders\",\n",
    "        \"minatar-asterix\",\n",
    "        \"minatar-seaquest\",\n",
    "    ] = \"minatar-breakout\"\n",
    "    seed: int = 0\n",
    "    lr: float = 0.0003\n",
    "    num_envs: int = 4096\n",
    "    num_eval_envs: int = 100\n",
    "    num_steps: int = 128\n",
    "    total_timesteps: int = 20_000_000\n",
    "    frame_skip: int = 1\n",
    "    update_epochs: int = 3\n",
    "    minibatch_size: int = 4096\n",
    "    gamma: float = 0.99\n",
    "    gae_lambda: float = 0.95\n",
    "    clip_eps: float = 0.2\n",
    "    ent_coef: float = 0.01\n",
    "    vf_coef: float = 0.5\n",
    "    max_grad_norm: float = 0.5\n",
    "    wandb_project: str = \"pgx-minatar-ppo\"\n",
    "    save_model: bool = True\n",
    "    \n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "\n",
    "# In Jupyter, directly create the config instead of parsing CLI args\n",
    "# You can override any default values here\n",
    "args = PPOConfig(\n",
    "    env_name=\"minatar-breakout\",  # Change this to test different games\n",
    "    num_envs=4096,  # Smaller for testing in notebook\n",
    "    total_timesteps=100000000,  # Shorter for testing\n",
    "    frame_skip = 6,\n",
    "    save_model=True,  # Don't save in notebook by default\n",
    ")\n",
    "print(f\"Config: {args}\")\n",
    "\n",
    "env = pgx.make(str(args.env_name))\n",
    "if args.env_name == \"minatar-freeway\":\n",
    "    print(\"using custom env\")\n",
    "    env = MinAtarFreeway(\n",
    "        use_minimal_action_set=True,\n",
    "        sticky_action_prob=0.1,\n",
    "        frame_skip=args.frame_skip,\n",
    "    )\n",
    "if args.env_name == \"minatar-breakout\":\n",
    "    env = MinAtarBreakout(\n",
    "        use_minimal_action_set=True,\n",
    "        sticky_action_prob=0.1,\n",
    "        frame_skip=args.frame_skip,\n",
    "    )\n",
    "\n",
    "num_updates = args.total_timesteps // args.num_envs // args.num_steps\n",
    "num_minibatches = args.num_envs * args.num_steps // args.minibatch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca816ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2826168/2208171417.py:362: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  config=args.dict() if hasattr(args, \"dict\") else vars(args),\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax/examples/minatar-ppo/wandb/run-20251029_154818-lzj9p0hy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo/runs/lzj9p0hy' target=\"_blank\">minatar-breakout-frameskip6</a></strong> to <a href='https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo' target=\"_blank\">https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo/runs/lzj9p0hy' target=\"_blank\">https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo/runs/lzj9p0hy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "{'sec': 6.764850378036499, 'minatar-breakout/eval_R': 0.22999998927116394, 'steps': 0}\n",
      "{'sec': 6.963831186294556, 'minatar-breakout/eval_R': 0.35999998450279236, 'steps': 524288}\n",
      "{'sec': 7.159559011459351, 'minatar-breakout/eval_R': 0.4099999964237213, 'steps': 1048576}\n",
      "{'sec': 7.3553783893585205, 'minatar-breakout/eval_R': 0.6299999952316284, 'steps': 1572864}\n",
      "{'sec': 7.551450490951538, 'minatar-breakout/eval_R': 0.9599999785423279, 'steps': 2097152}\n",
      "{'sec': 7.747801780700684, 'minatar-breakout/eval_R': 1.4299999475479126, 'steps': 2621440}\n",
      "{'sec': 7.943371295928955, 'minatar-breakout/eval_R': 1.2999999523162842, 'steps': 3145728}\n",
      "{'sec': 8.13919472694397, 'minatar-breakout/eval_R': 1.75, 'steps': 3670016}\n",
      "{'sec': 8.334853410720825, 'minatar-breakout/eval_R': 1.3899999856948853, 'steps': 4194304}\n",
      "{'sec': 8.530778169631958, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 4718592}\n",
      "{'sec': 8.726082563400269, 'minatar-breakout/eval_R': 1.6999999284744263, 'steps': 5242880}\n",
      "{'sec': 8.921623945236206, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 5767168}\n",
      "{'sec': 9.117393970489502, 'minatar-breakout/eval_R': 1.96999990940094, 'steps': 6291456}\n",
      "{'sec': 9.31381893157959, 'minatar-breakout/eval_R': 1.4800000190734863, 'steps': 6815744}\n",
      "{'sec': 9.509516954421997, 'minatar-breakout/eval_R': 1.75, 'steps': 7340032}\n",
      "{'sec': 9.704989671707153, 'minatar-breakout/eval_R': 1.2599999904632568, 'steps': 7864320}\n",
      "{'sec': 9.901180982589722, 'minatar-breakout/eval_R': 1.4800000190734863, 'steps': 8388608}\n",
      "{'sec': 10.097534418106079, 'minatar-breakout/eval_R': 1.7300000190734863, 'steps': 8912896}\n",
      "{'sec': 10.293070554733276, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 9437184}\n",
      "{'sec': 10.488879203796387, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 9961472}\n",
      "{'sec': 10.68510890007019, 'minatar-breakout/eval_R': 1.3299999237060547, 'steps': 10485760}\n",
      "{'sec': 10.880940198898315, 'minatar-breakout/eval_R': 1.4800000190734863, 'steps': 11010048}\n",
      "{'sec': 11.076252460479736, 'minatar-breakout/eval_R': 1.409999966621399, 'steps': 11534336}\n",
      "{'sec': 11.271945476531982, 'minatar-breakout/eval_R': 1.459999918937683, 'steps': 12058624}\n",
      "{'sec': 11.467997550964355, 'minatar-breakout/eval_R': 1.8199999332427979, 'steps': 12582912}\n",
      "{'sec': 11.664559602737427, 'minatar-breakout/eval_R': 1.7300000190734863, 'steps': 13107200}\n",
      "{'sec': 11.860395669937134, 'minatar-breakout/eval_R': 1.71999990940094, 'steps': 13631488}\n",
      "{'sec': 12.056315660476685, 'minatar-breakout/eval_R': 1.7400000095367432, 'steps': 14155776}\n",
      "{'sec': 12.252206802368164, 'minatar-breakout/eval_R': 1.2799999713897705, 'steps': 14680064}\n",
      "{'sec': 12.448418140411377, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 15204352}\n",
      "{'sec': 12.643442630767822, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 15728640}\n",
      "{'sec': 12.838432550430298, 'minatar-breakout/eval_R': 1.809999942779541, 'steps': 16252928}\n",
      "{'sec': 13.033550262451172, 'minatar-breakout/eval_R': 1.6399999856948853, 'steps': 16777216}\n",
      "{'sec': 13.229169845581055, 'minatar-breakout/eval_R': 1.3600000143051147, 'steps': 17301504}\n",
      "{'sec': 13.424307107925415, 'minatar-breakout/eval_R': 1.6799999475479126, 'steps': 17825792}\n",
      "{'sec': 13.620382070541382, 'minatar-breakout/eval_R': 1.5, 'steps': 18350080}\n",
      "{'sec': 13.816105604171753, 'minatar-breakout/eval_R': 1.5199999809265137, 'steps': 18874368}\n",
      "{'sec': 14.0119788646698, 'minatar-breakout/eval_R': 1.7300000190734863, 'steps': 19398656}\n",
      "{'sec': 14.207334280014038, 'minatar-breakout/eval_R': 1.9900000095367432, 'steps': 19922944}\n",
      "{'sec': 14.402431011199951, 'minatar-breakout/eval_R': 1.3899999856948853, 'steps': 20447232}\n",
      "{'sec': 14.59803032875061, 'minatar-breakout/eval_R': 1.7599999904632568, 'steps': 20971520}\n",
      "{'sec': 14.793745040893555, 'minatar-breakout/eval_R': 1.7799999713897705, 'steps': 21495808}\n",
      "{'sec': 14.9890775680542, 'minatar-breakout/eval_R': 1.559999942779541, 'steps': 22020096}\n",
      "{'sec': 15.184325456619263, 'minatar-breakout/eval_R': 1.8899999856948853, 'steps': 22544384}\n",
      "{'sec': 15.379794836044312, 'minatar-breakout/eval_R': 1.350000023841858, 'steps': 23068672}\n",
      "{'sec': 15.575502395629883, 'minatar-breakout/eval_R': 1.6100000143051147, 'steps': 23592960}\n",
      "{'sec': 15.771035432815552, 'minatar-breakout/eval_R': 1.5199999809265137, 'steps': 24117248}\n",
      "{'sec': 15.966333627700806, 'minatar-breakout/eval_R': 1.3399999141693115, 'steps': 24641536}\n",
      "{'sec': 16.162062644958496, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 25165824}\n",
      "{'sec': 16.358093738555908, 'minatar-breakout/eval_R': 1.2300000190734863, 'steps': 25690112}\n",
      "{'sec': 16.55311918258667, 'minatar-breakout/eval_R': 1.7599999904632568, 'steps': 26214400}\n",
      "{'sec': 16.74850296974182, 'minatar-breakout/eval_R': 1.4800000190734863, 'steps': 26738688}\n",
      "{'sec': 16.944051265716553, 'minatar-breakout/eval_R': 1.4199999570846558, 'steps': 27262976}\n",
      "{'sec': 17.139589309692383, 'minatar-breakout/eval_R': 1.409999966621399, 'steps': 27787264}\n",
      "{'sec': 17.335198402404785, 'minatar-breakout/eval_R': 1.4299999475479126, 'steps': 28311552}\n",
      "{'sec': 17.530420780181885, 'minatar-breakout/eval_R': 1.5799999237060547, 'steps': 28835840}\n",
      "{'sec': 17.72579002380371, 'minatar-breakout/eval_R': 1.5199999809265137, 'steps': 29360128}\n",
      "{'sec': 17.921810626983643, 'minatar-breakout/eval_R': 1.8199999332427979, 'steps': 29884416}\n",
      "{'sec': 18.11736226081848, 'minatar-breakout/eval_R': 1.649999976158142, 'steps': 30408704}\n",
      "{'sec': 18.312970399856567, 'minatar-breakout/eval_R': 1.8199999332427979, 'steps': 30932992}\n",
      "{'sec': 18.50866723060608, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 31457280}\n",
      "{'sec': 18.70423913002014, 'minatar-breakout/eval_R': 1.4299999475479126, 'steps': 31981568}\n",
      "{'sec': 18.899329900741577, 'minatar-breakout/eval_R': 1.6100000143051147, 'steps': 32505856}\n",
      "{'sec': 19.094496965408325, 'minatar-breakout/eval_R': 1.809999942779541, 'steps': 33030144}\n",
      "{'sec': 19.289783239364624, 'minatar-breakout/eval_R': 1.6899999380111694, 'steps': 33554432}\n",
      "{'sec': 19.48566222190857, 'minatar-breakout/eval_R': 2.059999942779541, 'steps': 34078720}\n",
      "{'sec': 19.679481267929077, 'minatar-breakout/eval_R': 1.5999999046325684, 'steps': 34603008}\n",
      "{'sec': 19.87345576286316, 'minatar-breakout/eval_R': 1.8600000143051147, 'steps': 35127296}\n",
      "{'sec': 20.06942892074585, 'minatar-breakout/eval_R': 1.8899999856948853, 'steps': 35651584}\n",
      "{'sec': 20.26569151878357, 'minatar-breakout/eval_R': 1.3799999952316284, 'steps': 36175872}\n",
      "{'sec': 20.460936307907104, 'minatar-breakout/eval_R': 1.4499999284744263, 'steps': 36700160}\n",
      "{'sec': 20.656395196914673, 'minatar-breakout/eval_R': 1.4499999284744263, 'steps': 37224448}\n",
      "{'sec': 20.851816177368164, 'minatar-breakout/eval_R': 1.3399999141693115, 'steps': 37748736}\n",
      "{'sec': 21.04740285873413, 'minatar-breakout/eval_R': 1.5999999046325684, 'steps': 38273024}\n",
      "{'sec': 21.242626190185547, 'minatar-breakout/eval_R': 1.4900000095367432, 'steps': 38797312}\n",
      "{'sec': 21.437856197357178, 'minatar-breakout/eval_R': 1.6899999380111694, 'steps': 39321600}\n",
      "{'sec': 21.635212898254395, 'minatar-breakout/eval_R': 1.7599999904632568, 'steps': 39845888}\n",
      "{'sec': 21.831268310546875, 'minatar-breakout/eval_R': 1.309999942779541, 'steps': 40370176}\n",
      "{'sec': 22.026594400405884, 'minatar-breakout/eval_R': 1.6899999380111694, 'steps': 40894464}\n",
      "{'sec': 22.221630096435547, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 41418752}\n",
      "{'sec': 22.41695475578308, 'minatar-breakout/eval_R': 1.7799999713897705, 'steps': 41943040}\n",
      "{'sec': 22.61253833770752, 'minatar-breakout/eval_R': 1.5, 'steps': 42467328}\n",
      "{'sec': 22.80800199508667, 'minatar-breakout/eval_R': 1.5399999618530273, 'steps': 42991616}\n",
      "{'sec': 23.003643035888672, 'minatar-breakout/eval_R': 1.5, 'steps': 43515904}\n",
      "{'sec': 23.19925880432129, 'minatar-breakout/eval_R': 1.5799999237060547, 'steps': 44040192}\n",
      "{'sec': 23.3947594165802, 'minatar-breakout/eval_R': 1.3600000143051147, 'steps': 44564480}\n",
      "{'sec': 23.589866638183594, 'minatar-breakout/eval_R': 1.5799999237060547, 'steps': 45088768}\n",
      "{'sec': 23.784926176071167, 'minatar-breakout/eval_R': 1.5, 'steps': 45613056}\n",
      "{'sec': 23.98096489906311, 'minatar-breakout/eval_R': 1.5499999523162842, 'steps': 46137344}\n",
      "{'sec': 24.17728352546692, 'minatar-breakout/eval_R': 1.659999966621399, 'steps': 46661632}\n",
      "{'sec': 24.373230457305908, 'minatar-breakout/eval_R': 1.7400000095367432, 'steps': 47185920}\n",
      "{'sec': 24.568590879440308, 'minatar-breakout/eval_R': 1.46999990940094, 'steps': 47710208}\n",
      "{'sec': 24.76472043991089, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 48234496}\n",
      "{'sec': 24.960130214691162, 'minatar-breakout/eval_R': 1.7999999523162842, 'steps': 48758784}\n",
      "{'sec': 25.155712842941284, 'minatar-breakout/eval_R': 1.6999999284744263, 'steps': 49283072}\n",
      "{'sec': 25.351539373397827, 'minatar-breakout/eval_R': 1.899999976158142, 'steps': 49807360}\n",
      "{'sec': 25.547334671020508, 'minatar-breakout/eval_R': 1.3199999332427979, 'steps': 50331648}\n",
      "{'sec': 25.741666316986084, 'minatar-breakout/eval_R': 1.5999999046325684, 'steps': 50855936}\n",
      "{'sec': 25.937362670898438, 'minatar-breakout/eval_R': 1.4900000095367432, 'steps': 51380224}\n",
      "{'sec': 26.133162260055542, 'minatar-breakout/eval_R': 1.4199999570846558, 'steps': 51904512}\n",
      "{'sec': 26.328898668289185, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 52428800}\n",
      "{'sec': 26.524882316589355, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 52953088}\n",
      "{'sec': 26.720459699630737, 'minatar-breakout/eval_R': 1.6899999380111694, 'steps': 53477376}\n",
      "{'sec': 26.916025638580322, 'minatar-breakout/eval_R': 1.3199999332427979, 'steps': 54001664}\n",
      "{'sec': 27.111595392227173, 'minatar-breakout/eval_R': 1.6999999284744263, 'steps': 54525952}\n",
      "{'sec': 27.307376384735107, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 55050240}\n",
      "{'sec': 27.503166913986206, 'minatar-breakout/eval_R': 1.8700000047683716, 'steps': 55574528}\n",
      "{'sec': 27.698912143707275, 'minatar-breakout/eval_R': 1.4900000095367432, 'steps': 56098816}\n",
      "{'sec': 27.89457893371582, 'minatar-breakout/eval_R': 1.4199999570846558, 'steps': 56623104}\n",
      "{'sec': 28.088785409927368, 'minatar-breakout/eval_R': 1.2300000190734863, 'steps': 57147392}\n",
      "{'sec': 28.28420877456665, 'minatar-breakout/eval_R': 1.75, 'steps': 57671680}\n",
      "{'sec': 28.478567838668823, 'minatar-breakout/eval_R': 1.5699999332427979, 'steps': 58195968}\n",
      "{'sec': 28.674243450164795, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 58720256}\n",
      "{'sec': 28.869898319244385, 'minatar-breakout/eval_R': 1.9499999284744263, 'steps': 59244544}\n",
      "{'sec': 29.065500020980835, 'minatar-breakout/eval_R': 1.4900000095367432, 'steps': 59768832}\n",
      "{'sec': 29.261284828186035, 'minatar-breakout/eval_R': 1.5699999332427979, 'steps': 60293120}\n",
      "{'sec': 29.45685887336731, 'minatar-breakout/eval_R': 1.709999918937683, 'steps': 60817408}\n",
      "{'sec': 29.652647972106934, 'minatar-breakout/eval_R': 1.2599999904632568, 'steps': 61341696}\n",
      "{'sec': 29.848273038864136, 'minatar-breakout/eval_R': 1.5799999237060547, 'steps': 61865984}\n",
      "{'sec': 30.043614387512207, 'minatar-breakout/eval_R': 1.7300000190734863, 'steps': 62390272}\n",
      "{'sec': 30.239174604415894, 'minatar-breakout/eval_R': 1.5699999332427979, 'steps': 62914560}\n",
      "{'sec': 30.43515706062317, 'minatar-breakout/eval_R': 1.2699999809265137, 'steps': 63438848}\n",
      "{'sec': 30.63090682029724, 'minatar-breakout/eval_R': 1.5799999237060547, 'steps': 63963136}\n",
      "{'sec': 30.824824810028076, 'minatar-breakout/eval_R': 1.7599999904632568, 'steps': 64487424}\n",
      "{'sec': 31.020815134048462, 'minatar-breakout/eval_R': 1.659999966621399, 'steps': 65011712}\n",
      "{'sec': 31.21684503555298, 'minatar-breakout/eval_R': 1.8299999237060547, 'steps': 65536000}\n",
      "{'sec': 31.412704467773438, 'minatar-breakout/eval_R': 1.5899999141693115, 'steps': 66060288}\n",
      "{'sec': 31.608566999435425, 'minatar-breakout/eval_R': 1.5499999523162842, 'steps': 66584576}\n",
      "{'sec': 31.804118156433105, 'minatar-breakout/eval_R': 1.4299999475479126, 'steps': 67108864}\n",
      "{'sec': 32.00003242492676, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 67633152}\n",
      "{'sec': 32.195359230041504, 'minatar-breakout/eval_R': 1.309999942779541, 'steps': 68157440}\n",
      "{'sec': 32.39138102531433, 'minatar-breakout/eval_R': 1.809999942779541, 'steps': 68681728}\n",
      "{'sec': 32.587231397628784, 'minatar-breakout/eval_R': 1.9900000095367432, 'steps': 69206016}\n",
      "{'sec': 32.78328466415405, 'minatar-breakout/eval_R': 1.5199999809265137, 'steps': 69730304}\n",
      "{'sec': 32.979249000549316, 'minatar-breakout/eval_R': 1.7799999713897705, 'steps': 70254592}\n",
      "{'sec': 33.173152923583984, 'minatar-breakout/eval_R': 1.559999942779541, 'steps': 70778880}\n",
      "{'sec': 33.368890047073364, 'minatar-breakout/eval_R': 1.809999942779541, 'steps': 71303168}\n",
      "{'sec': 33.56457161903381, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 71827456}\n",
      "{'sec': 33.76032495498657, 'minatar-breakout/eval_R': 1.3799999952316284, 'steps': 72351744}\n",
      "{'sec': 33.955183029174805, 'minatar-breakout/eval_R': 1.9399999380111694, 'steps': 72876032}\n",
      "{'sec': 34.150394439697266, 'minatar-breakout/eval_R': 1.649999976158142, 'steps': 73400320}\n",
      "{'sec': 34.345659494400024, 'minatar-breakout/eval_R': 1.6699999570846558, 'steps': 73924608}\n",
      "{'sec': 34.539490938186646, 'minatar-breakout/eval_R': 1.649999976158142, 'steps': 74448896}\n",
      "{'sec': 34.73535919189453, 'minatar-breakout/eval_R': 1.6699999570846558, 'steps': 74973184}\n",
      "{'sec': 34.92976641654968, 'minatar-breakout/eval_R': 1.7400000095367432, 'steps': 75497472}\n",
      "{'sec': 35.12614965438843, 'minatar-breakout/eval_R': 1.71999990940094, 'steps': 76021760}\n",
      "{'sec': 35.32116079330444, 'minatar-breakout/eval_R': 1.4800000190734863, 'steps': 76546048}\n",
      "{'sec': 35.51709342002869, 'minatar-breakout/eval_R': 1.6999999284744263, 'steps': 77070336}\n",
      "{'sec': 35.71182918548584, 'minatar-breakout/eval_R': 1.809999942779541, 'steps': 77594624}\n",
      "{'sec': 35.90604281425476, 'minatar-breakout/eval_R': 1.7999999523162842, 'steps': 78118912}\n",
      "{'sec': 36.10158896446228, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 78643200}\n",
      "{'sec': 36.29713416099548, 'minatar-breakout/eval_R': 1.4399999380111694, 'steps': 79167488}\n",
      "{'sec': 36.492218255996704, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 79691776}\n",
      "{'sec': 36.688103914260864, 'minatar-breakout/eval_R': 1.649999976158142, 'steps': 80216064}\n",
      "{'sec': 36.88375115394592, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 80740352}\n",
      "{'sec': 37.079458236694336, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 81264640}\n",
      "{'sec': 37.27530574798584, 'minatar-breakout/eval_R': 1.4399999380111694, 'steps': 81788928}\n",
      "{'sec': 37.471009969711304, 'minatar-breakout/eval_R': 1.6999999284744263, 'steps': 82313216}\n",
      "{'sec': 37.66576647758484, 'minatar-breakout/eval_R': 1.7400000095367432, 'steps': 82837504}\n",
      "{'sec': 37.86054301261902, 'minatar-breakout/eval_R': 1.350000023841858, 'steps': 83361792}\n",
      "{'sec': 38.05534338951111, 'minatar-breakout/eval_R': 1.6299999952316284, 'steps': 83886080}\n",
      "{'sec': 38.24971008300781, 'minatar-breakout/eval_R': 1.75, 'steps': 84410368}\n",
      "{'sec': 38.44369173049927, 'minatar-breakout/eval_R': 1.75, 'steps': 84934656}\n",
      "{'sec': 38.63936758041382, 'minatar-breakout/eval_R': 1.5, 'steps': 85458944}\n",
      "{'sec': 38.83517575263977, 'minatar-breakout/eval_R': 1.6999999284744263, 'steps': 85983232}\n",
      "{'sec': 39.031412839889526, 'minatar-breakout/eval_R': 1.5199999809265137, 'steps': 86507520}\n",
      "{'sec': 39.227232694625854, 'minatar-breakout/eval_R': 1.6399999856948853, 'steps': 87031808}\n",
      "{'sec': 39.423019886016846, 'minatar-breakout/eval_R': 1.5099999904632568, 'steps': 87556096}\n",
      "{'sec': 39.617767572402954, 'minatar-breakout/eval_R': 1.459999918937683, 'steps': 88080384}\n",
      "{'sec': 39.81383037567139, 'minatar-breakout/eval_R': 1.3199999332427979, 'steps': 88604672}\n",
      "{'sec': 40.00902438163757, 'minatar-breakout/eval_R': 1.0499999523162842, 'steps': 89128960}\n",
      "{'sec': 40.2050678730011, 'minatar-breakout/eval_R': 1.6200000047683716, 'steps': 89653248}\n",
      "{'sec': 40.40048384666443, 'minatar-breakout/eval_R': 1.4499999284744263, 'steps': 90177536}\n",
      "{'sec': 40.594794511795044, 'minatar-breakout/eval_R': 1.8899999856948853, 'steps': 90701824}\n",
      "{'sec': 40.790032625198364, 'minatar-breakout/eval_R': 1.649999976158142, 'steps': 91226112}\n",
      "{'sec': 40.98425841331482, 'minatar-breakout/eval_R': 1.4900000095367432, 'steps': 91750400}\n",
      "{'sec': 41.18003988265991, 'minatar-breakout/eval_R': 1.7699999809265137, 'steps': 92274688}\n",
      "{'sec': 41.37534284591675, 'minatar-breakout/eval_R': 1.3600000143051147, 'steps': 92798976}\n",
      "{'sec': 41.56965970993042, 'minatar-breakout/eval_R': 1.5699999332427979, 'steps': 93323264}\n",
      "{'sec': 41.76555275917053, 'minatar-breakout/eval_R': 1.209999918937683, 'steps': 93847552}\n",
      "{'sec': 41.961851358413696, 'minatar-breakout/eval_R': 1.8299999237060547, 'steps': 94371840}\n",
      "{'sec': 42.15712833404541, 'minatar-breakout/eval_R': 1.46999990940094, 'steps': 94896128}\n",
      "{'sec': 42.35144400596619, 'minatar-breakout/eval_R': 1.5999999046325684, 'steps': 95420416}\n",
      "{'sec': 42.546982288360596, 'minatar-breakout/eval_R': 1.7599999904632568, 'steps': 95944704}\n",
      "{'sec': 42.74306774139404, 'minatar-breakout/eval_R': 1.6899999380111694, 'steps': 96468992}\n",
      "{'sec': 42.938976526260376, 'minatar-breakout/eval_R': 1.5299999713897705, 'steps': 96993280}\n",
      "{'sec': 43.13382625579834, 'minatar-breakout/eval_R': 1.5999999046325684, 'steps': 97517568}\n",
      "{'sec': 43.32791614532471, 'minatar-breakout/eval_R': 1.2699999809265137, 'steps': 98041856}\n",
      "{'sec': 43.52288603782654, 'minatar-breakout/eval_R': 1.75, 'steps': 98566144}\n",
      "{'sec': 43.71826767921448, 'minatar-breakout/eval_R': 1.46999990940094, 'steps': 99090432}\n",
      "{'sec': 43.91431474685669, 'minatar-breakout/eval_R': 1.4499999284744263, 'steps': 99614720}\n",
      "Model saved to minatar-breakout-seed=0-notebook.ckpt\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>minatar-breakout/eval_R</td><td>▁▁▄▆▅▇▅▅▆█▅▆▆▇▇▆▆▇▅▆▆▇▆▇▆▆▆▆▇▆▆▅▇▇▆▆█▇▇▇</td></tr><tr><td>sec</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>steps</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>minatar-breakout/eval_R</td><td>1.45</td></tr><tr><td>sec</td><td>43.91431</td></tr><tr><td>steps</td><td>99614720</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">minatar-breakout-frameskip6</strong> at: <a href='https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo/runs/lzj9p0hy' target=\"_blank\">https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo/runs/lzj9p0hy</a><br> View project at: <a href='https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo' target=\"_blank\">https://wandb.ai/aneeshmuppidi19/pgx-minatar-ppo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251029_154818-lzj9p0hy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"This PPO implementation is modified from PureJaxRL:\n",
    "\n",
    "    https://github.com/luchris429/purejaxrl\n",
    "\n",
    "Please refer to their work if you use this example in your research.\"\"\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from functools import partial\n",
    "from typing import NamedTuple, Literal\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import nnx\n",
    "import wandb\n",
    "\n",
    "import pgx\n",
    "from pgx.experimental import auto_reset\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Simple Categorical distribution wrapper using JAX built-ins\n",
    "# -----------------------------\n",
    "class Categorical:\n",
    "    def __init__(self, logits):\n",
    "        self.logits = logits\n",
    "\n",
    "    def sample(self, seed):\n",
    "        return jax.random.categorical(seed, self.logits)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        log_probs = jax.nn.log_softmax(self.logits)\n",
    "        return jnp.take_along_axis(log_probs, value[..., None], axis=-1).squeeze(-1)\n",
    "\n",
    "    def entropy(self):\n",
    "        log_probs = jax.nn.log_softmax(self.logits)\n",
    "        probs = jax.nn.softmax(self.logits)\n",
    "        return -(probs * log_probs).sum(axis=-1)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# NNX Actor-Critic\n",
    "# -----------------------------\n",
    "def pool_out_dim(n: int, window: int = 2, stride: int = 2, padding: str = \"VALID\") -> int:\n",
    "    # Matches flax.linen/nnx pooling semantics for VALID padding\n",
    "    if padding.upper() == \"VALID\":\n",
    "        return (n - window) // stride + 1\n",
    "    # Fallback (not used here)\n",
    "    return math.ceil(n / stride)\n",
    "\n",
    "\n",
    "class ActorCritic(nnx.Module):\n",
    "    def __init__(self, num_actions: int, obs_shape, activation: str = \"tanh\", *, rngs: nnx.Rngs):\n",
    "        assert activation in [\"relu\", \"tanh\"]\n",
    "        self.num_actions = num_actions\n",
    "        self.activation = activation\n",
    "\n",
    "        H, W, C = obs_shape  # NHWC expected by flax.nnx.Conv\n",
    "        # Convolution (channels-last). Default padding is 'SAME'.\n",
    "        self.conv = nnx.Conv(in_features=C, out_features=32, kernel_size=(2, 2), rngs=rngs)\n",
    "\n",
    "        # AvgPool params are fixed; keep a partial for clean callsites\n",
    "        self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2), padding=\"VALID\")\n",
    "\n",
    "        # After conv ('SAME') + avg_pool('VALID', 2x2, stride 2) the spatial dims become:\n",
    "        H2 = pool_out_dim(H, 2, 2, \"VALID\")\n",
    "        W2 = pool_out_dim(W, 2, 2, \"VALID\")\n",
    "        flatten_dim = H2 * W2 * 32\n",
    "\n",
    "        # Shared torso\n",
    "        self.fc = nnx.Linear(flatten_dim, 64, rngs=rngs)\n",
    "\n",
    "        # Actor head: 64 -> 64 -> 64 -> num_actions (two hidden layers like original)\n",
    "        self.actor_h1 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.actor_h2 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.actor_out = nnx.Linear(64, num_actions, rngs=rngs)\n",
    "\n",
    "        # Critic head: 64 -> 64 -> 64 -> 1 (two hidden layers like original)\n",
    "        self.critic_h1 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.critic_h2 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.critic_out = nnx.Linear(64, 1, rngs=rngs)\n",
    "\n",
    "    def _act(self, x):\n",
    "        return nnx.relu(x) if self.activation == \"relu\" else nnx.tanh(x)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.astype(jnp.float32)\n",
    "        x = self.conv(x)\n",
    "        x = nnx.relu(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nnx.relu(self.fc(x))\n",
    "\n",
    "        a = self._act(self.actor_h1(x))\n",
    "        a = self._act(self.actor_h2(a))\n",
    "        logits = self.actor_out(a)\n",
    "\n",
    "        v = self._act(self.critic_h1(x))\n",
    "        v = self._act(self.critic_h2(v))\n",
    "        value = self.critic_out(v)\n",
    "\n",
    "        return logits, jnp.squeeze(value, axis=-1)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Optimizer (Optax via NNX wrapper)\n",
    "# -----------------------------\n",
    "tx = optax.chain(\n",
    "    optax.clip_by_global_norm(args.max_grad_norm),\n",
    "    optax.adam(args.lr, eps=1e-5),\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Rollout container\n",
    "# -----------------------------\n",
    "class Transition(NamedTuple):\n",
    "    done: jnp.ndarray\n",
    "    action: jnp.ndarray\n",
    "    value: jnp.ndarray\n",
    "    reward: jnp.ndarray\n",
    "    log_prob: jnp.ndarray\n",
    "    obs: jnp.ndarray\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Update step (collect + optimize), jitted with NNX\n",
    "# -----------------------------\n",
    "def make_update_step():\n",
    "    step_fn = jax.vmap(auto_reset(env.step, env.init))\n",
    "\n",
    "    @nnx.jit(donate_argnames=(\"model\", \"optimizer\"))\n",
    "    def _update_step(model: nnx.Module,\n",
    "                    optimizer: nnx.Optimizer,\n",
    "                    env_state,\n",
    "                    last_obs,\n",
    "                    rng):\n",
    "        # -------- Collect trajectories --------\n",
    "        def _env_step(runner_state, _):\n",
    "            model, optimizer, env_state, last_obs, rng = runner_state\n",
    "\n",
    "            # Policy\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            logits, value = model(last_obs)\n",
    "            pi = Categorical(logits=logits)\n",
    "            action = pi.sample(seed=_rng)\n",
    "            log_prob = pi.log_prob(action)\n",
    "\n",
    "            # Env step\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            keys = jax.random.split(_rng, env_state.observation.shape[0])\n",
    "            env_state = step_fn(env_state, action, keys)\n",
    "\n",
    "            transition = Transition(\n",
    "                env_state.terminated,\n",
    "                action,\n",
    "                value,\n",
    "                jnp.squeeze(env_state.rewards),\n",
    "                log_prob,\n",
    "                last_obs,\n",
    "            )\n",
    "            runner_state = (model, optimizer, env_state, env_state.observation, rng)\n",
    "            return runner_state, transition\n",
    "\n",
    "        runner_state = (model, optimizer, env_state, last_obs, rng)\n",
    "        runner_state, traj_batch = jax.lax.scan(_env_step, runner_state, None, length=args.num_steps)\n",
    "\n",
    "        # -------- Advantage / targets (GAE) --------\n",
    "        model, optimizer, env_state, last_obs, rng = runner_state\n",
    "        _, last_val = model(last_obs)\n",
    "\n",
    "        def _get_advantages(gae_and_next_value, transition):\n",
    "            gae, next_value = gae_and_next_value\n",
    "            done, value, reward = transition.done, transition.value, transition.reward\n",
    "            delta = reward + args.gamma * next_value * (1 - done) - value\n",
    "            gae = delta + args.gamma * args.gae_lambda * (1 - done) * gae\n",
    "            return (gae, value), gae\n",
    "\n",
    "        (_, _), advantages = jax.lax.scan(\n",
    "            _get_advantages,\n",
    "            (jnp.zeros_like(last_val), last_val),\n",
    "            traj_batch,\n",
    "            reverse=True,\n",
    "            unroll=16,\n",
    "        )\n",
    "        targets = advantages + traj_batch.value\n",
    "\n",
    "        # -------- SGD epochs --------\n",
    "        def _update_epoch(update_state, _):\n",
    "            model, optimizer, traj_batch, advantages, targets, rng = update_state\n",
    "\n",
    "            def _update_minibatch(state, minibatch):\n",
    "                model, optimizer = state\n",
    "                mb_traj, mb_adv, mb_targets = minibatch\n",
    "\n",
    "                def _loss_fn(model: nnx.Module, traj: Transition, gae, targets):\n",
    "                    # Re-run policy\n",
    "                    logits, value = model(traj.obs)\n",
    "                    pi = Categorical(logits=logits)\n",
    "                    log_prob = pi.log_prob(traj.action)\n",
    "\n",
    "                    # Value loss (clipped)\n",
    "                    value_pred_clipped = traj.value + (value - traj.value).clip(-args.clip_eps, args.clip_eps)\n",
    "                    v_loss_unclipped = jnp.square(value - targets)\n",
    "                    v_loss_clipped = jnp.square(value_pred_clipped - targets)\n",
    "                    value_loss = 0.5 * jnp.maximum(v_loss_unclipped, v_loss_clipped).mean()\n",
    "\n",
    "                    # Policy loss (clipped)\n",
    "                    ratio = jnp.exp(log_prob - traj.log_prob)\n",
    "                    gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
    "                    loss_actor1 = ratio * gae\n",
    "                    loss_actor2 = jnp.clip(ratio, 1.0 - args.clip_eps, 1.0 + args.clip_eps) * gae\n",
    "                    loss_actor = -jnp.minimum(loss_actor1, loss_actor2).mean()\n",
    "\n",
    "                    # Entropy bonus\n",
    "                    entropy = pi.entropy().mean()\n",
    "\n",
    "                    total = loss_actor + args.vf_coef * value_loss - args.ent_coef * entropy\n",
    "                    return total, (value_loss, loss_actor, entropy)\n",
    "\n",
    "                # Compute grads w.r.t. model Params\n",
    "                (total_loss, aux), grads = nnx.value_and_grad(\n",
    "                    _loss_fn, has_aux=True, argnums=nnx.DiffState(0, nnx.Param)\n",
    "                )(model, mb_traj, mb_adv, mb_targets)\n",
    "\n",
    "                # Optax step via NNX Optimizer (updates model in-place)\n",
    "                optimizer.update(model, grads)\n",
    "\n",
    "                return (model, optimizer), (total_loss, aux)\n",
    "\n",
    "            # Shuffle + minibatch\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            batch_size = args.minibatch_size * num_minibatches\n",
    "            assert batch_size == args.num_steps * args.num_envs, \"batch size must equal steps * envs\"\n",
    "\n",
    "            batch = (traj_batch, advantages, targets)\n",
    "            batch = jax.tree.map(lambda x: x.reshape((batch_size,) + x.shape[2:]), batch)\n",
    "            permutation = jax.random.permutation(_rng, batch_size)\n",
    "            shuffled = jax.tree.map(lambda x: jnp.take(x, permutation, axis=0), batch)\n",
    "            minibatches = jax.tree.map(\n",
    "                lambda x: jnp.reshape(x, [num_minibatches, -1] + list(x.shape[1:])),\n",
    "                shuffled,\n",
    "            )\n",
    "\n",
    "            (model, optimizer), losses = jax.lax.scan(_update_minibatch, (model, optimizer), minibatches)\n",
    "            update_state = (model, optimizer, traj_batch, advantages, targets, rng)\n",
    "            return update_state, losses\n",
    "\n",
    "        update_state = (model, optimizer, traj_batch, advantages, targets, rng)\n",
    "        update_state, loss_info = jax.lax.scan(_update_epoch, update_state, None, length=args.update_epochs)\n",
    "\n",
    "        model, optimizer, _, _, _, rng = update_state\n",
    "        runner_state = (model, optimizer, env_state, last_obs, rng)\n",
    "        return runner_state, loss_info\n",
    "\n",
    "    return _update_step\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation (greedy sample)\n",
    "# -----------------------------\n",
    "@nnx.jit\n",
    "def evaluate(model: nnx.Module, rng_key):\n",
    "    step_fn = jax.vmap(env.step)\n",
    "    rng_key, sub_key = jax.random.split(rng_key)\n",
    "    subkeys = jax.random.split(sub_key, args.num_eval_envs)\n",
    "    state = jax.vmap(env.init)(subkeys)\n",
    "    R = jnp.zeros_like(state.rewards)\n",
    "\n",
    "    def cond_fn(tup):\n",
    "        state, _, _ = tup\n",
    "        return ~state.terminated.all()\n",
    "\n",
    "    def loop_fn(tup):\n",
    "        state, R, rng_key = tup\n",
    "        logits, _value = model(state.observation)\n",
    "        pi = Categorical(logits=logits)\n",
    "        rng_key, _rng = jax.random.split(rng_key)\n",
    "        action = pi.sample(seed=_rng)\n",
    "        rng_key, _rng = jax.random.split(rng_key)\n",
    "        keys = jax.random.split(_rng, state.observation.shape[0])\n",
    "        state = step_fn(state, action, keys)\n",
    "        return state, R + state.rewards, rng_key\n",
    "\n",
    "    state, R, _ = jax.lax.while_loop(cond_fn, loop_fn, (state, R, rng_key))\n",
    "    return R.mean()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training Loop\n",
    "# -----------------------------\n",
    "def train(rng):\n",
    "    tt = 0.0\n",
    "    st = time.time()\n",
    "\n",
    "    # Model + optimizer\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    obs_shape = env.observation_shape\n",
    "    model = ActorCritic(env.num_actions, obs_shape=obs_shape, activation=\"tanh\", rngs=nnx.Rngs(_rng))\n",
    "    optimizer = nnx.Optimizer(model, tx, wrt=nnx.Param)\n",
    "\n",
    "    # Update function\n",
    "    update_step = make_update_step()\n",
    "\n",
    "    # Init envs\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    reset_rng = jax.random.split(_rng, args.num_envs)\n",
    "    env_state = jax.jit(jax.vmap(env.init))(reset_rng)\n",
    "    last_obs = env_state.observation\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    runner_state = (model, optimizer, env_state, last_obs, _rng)\n",
    "\n",
    "    # Warmup (compile)\n",
    "    _, _ = update_step(*runner_state)\n",
    "\n",
    "    # initial evaluation\n",
    "    et = time.time()\n",
    "    tt += et - st\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    eval_R = evaluate(runner_state[0], _rng)\n",
    "    steps = 0\n",
    "    log = {\"sec\": tt, f\"{args.env_name}/eval_R\": float(eval_R), \"steps\": steps}\n",
    "    print(log)\n",
    "\n",
    "    # Only log to wandb if initialized\n",
    "    if wandb.run is not None:\n",
    "        wandb.log(log)\n",
    "    st = time.time()\n",
    "\n",
    "    for _ in range(num_updates):\n",
    "        runner_state, loss_info = update_step(*runner_state)\n",
    "        model, optimizer, env_state, last_obs, rng = runner_state\n",
    "        steps += args.num_envs * args.num_steps\n",
    "\n",
    "        # evaluation\n",
    "        et = time.time()\n",
    "        tt += et - st\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        eval_R = evaluate(model, _rng)\n",
    "        log = {\"sec\": tt, f\"{args.env_name}/eval_R\": float(eval_R), \"steps\": steps}\n",
    "        print(log)\n",
    "\n",
    "        # Only log to wandb if initialized\n",
    "        if wandb.run is not None:\n",
    "            wandb.log(log)\n",
    "        st = time.time()\n",
    "\n",
    "    return runner_state  # (model, optimizer, env_state, last_obs, rng)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run training (for notebook execution)\n",
    "# -----------------------------\n",
    "# Or run without wandb\n",
    "wandb.init(\n",
    "    project=args.wandb_project,        # \"pgx-minatar-ppo\" by default\n",
    "    name=f\"{args.env_name}-frameskip{args.frame_skip}\",\n",
    "    config=args.dict() if hasattr(args, \"dict\") else vars(args),\n",
    ")\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "rng = jax.random.PRNGKey(args.seed)\n",
    "runner_state = train(rng)\n",
    "\n",
    "# Save model if desired\n",
    "if args.save_model:\n",
    "    model = runner_state[0]\n",
    "    # Save only learnable parameters\n",
    "    with open(f\"{args.env_name}-seed={args.seed}-notebook.ckpt\", \"wb\") as f:\n",
    "        pickle.dump(nnx.state(model, nnx.Param), f)\n",
    "    print(f\"Model saved to {args.env_name}-seed={args.seed}-notebook.ckpt\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db492f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45149f1892b417c97d74c399a193f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating rollout:   0%|                               | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving video to minatar-breakout-frameskip6.gif ...\n",
      "Saved 8 frames to minatar-breakout-frameskip6.gif\n",
      "Mean reward: 2.250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from pgx.minatar.utils import visualize_minatar  # patched version supports fmt=\"png\"\n",
    "import io\n",
    "import imageio.v2 as imageio\n",
    "ENV_NAME = args.env_name\n",
    "CKPT_PATH = f\"/home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax/examples/minatar-ppo/{ENV_NAME}-seed=0-notebook.ckpt\"\n",
    "OUTPUT_GIF = f\"{ENV_NAME}-frameskip{args.frame_skip}.gif\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# -------------------------------------------------------------------------\n",
    "def build_model(env, rng):\n",
    "    obs_shape = env.observation_shape\n",
    "    return ActorCritic(env.num_actions, obs_shape=obs_shape, activation=\"tanh\", rngs=nnx.Rngs(rng))\n",
    "\n",
    "def load_model(env, ckpt_path: str, rng):\n",
    "    \"\"\"Recreate module and load nnx.Param state.\"\"\"\n",
    "    model = build_model(env, rng)\n",
    "    with open(ckpt_path, \"rb\") as f:\n",
    "        param_state = pickle.load(f)\n",
    "    nnx.update(model, param_state)\n",
    "    return model\n",
    "\n",
    "def eval_rollout_and_save_video(model: nnx.Module,\n",
    "                                env,\n",
    "                                rng_key,\n",
    "                                num_envs_to_render: int = 16,\n",
    "                                max_steps: int = 500,\n",
    "                                fps: int = 8,\n",
    "                                output_gif: str = \"eval.gif\"):\n",
    "    \"\"\"\n",
    "    Runs a non-jitted rollout for rendering & saves GIF locally.\n",
    "    \"\"\"\n",
    "    rng_key, sub_key = jax.random.split(rng_key)\n",
    "    subkeys = jax.random.split(sub_key, num_envs_to_render)\n",
    "    state = jax.vmap(env.init)(subkeys)\n",
    "    total_R = jnp.zeros_like(state.rewards)\n",
    "    frames_png = []\n",
    "\n",
    "    # tqdm progress bar\n",
    "    for t in tqdm(range(max_steps), desc=\"Evaluating rollout\", ncols=80):\n",
    "        # Render frame\n",
    "        png_bytes = visualize_minatar(state, savefile=None, fmt=\"png\", dpi=160)\n",
    "        frames_png.append(png_bytes)\n",
    "\n",
    "        # Policy step\n",
    "        logits, _ = model(state.observation)\n",
    "        rng_key, _rng = jax.random.split(rng_key)\n",
    "        action = Categorical(logits).sample(seed=_rng)\n",
    "\n",
    "        # Env step\n",
    "        rng_key, _rng = jax.random.split(rng_key)\n",
    "        keys = jax.random.split(_rng, state.observation.shape[0])\n",
    "        state = jax.vmap(env.step)(state, action, keys)\n",
    "\n",
    "        total_R = total_R + state.rewards\n",
    "        if bool(state.terminated.all()):\n",
    "            break\n",
    "\n",
    "    # Convert PNGs → GIF\n",
    "    print(f\"\\nSaving video to {output_gif} ...\")\n",
    "    imgs = [imageio.imread(io.BytesIO(b)) for b in frames_png]\n",
    "    imgs = [im[..., :3] if im.ndim == 3 and im.shape[-1] == 4 else im for im in imgs]\n",
    "    imageio.mimsave(output_gif, imgs, fps=fps)\n",
    "    print(f\"Saved {len(imgs)} frames to {output_gif}\")\n",
    "    print(f\"Mean reward: {float(total_R.mean()):.3f}\")\n",
    "    return float(total_R.mean())\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Main entry\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(env.frame_skip)\n",
    "rng = jax.random.PRNGKey(123)\n",
    "rng, load_rng = jax.random.split(rng)\n",
    "\n",
    "model = load_model(env, CKPT_PATH, load_rng)\n",
    "\n",
    "rng, eval_rng = jax.random.split(rng)\n",
    "eval_rollout_and_save_video(\n",
    "    model,\n",
    "    env,\n",
    "    rng_key=eval_rng,\n",
    "    num_envs_to_render=4,\n",
    "    max_steps=200,\n",
    "    fps=60,\n",
    "    output_gif=OUTPUT_GIF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa738312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STA] agent_hz=  261.4 | ticks=144 return=20.000\n",
      "[STA] agent_hz=  259.1 | ticks=290 return=30.000\n",
      "[STA] agent_hz=  260.3 | ticks=432 return=46.000\n",
      "[STA] agent_hz=  260.4 | ticks=576 return=57.000\n",
      "[STA] agent_hz=  260.9 | ticks=719 return=74.000\n",
      "[STA] agent_hz=  259.0 | ticks=869 return=88.000\n",
      "[STA] agent_hz=  259.3 | ticks=1012 return=104.000\n",
      "[STA] agent_hz=  259.5 | ticks=1156 return=117.000\n",
      "[STA] agent_hz=  259.8 | ticks=1299 return=132.000\n",
      "[STA] agent_hz=  260.0 | ticks=1443 return=147.000\n",
      "[STA] agent_hz=  260.3 | ticks=1585 return=159.000\n",
      "[STA] agent_hz=  260.4 | ticks=1729 return=176.000\n",
      "[STA] agent_hz=  260.1 | ticks=1874 return=187.000\n",
      "[STA] agent_hz=  260.1 | ticks=2018 return=206.000\n",
      "[STA] agent_hz=  260.3 | ticks=2161 return=217.000\n",
      "[STA] agent_hz=  259.6 | ticks=2311 return=236.000\n",
      "[STA] agent_hz=  259.7 | ticks=2455 return=247.000\n",
      "[STA] agent_hz=  258.7 | ticks=2609 return=267.000\n",
      "[STA] agent_hz=  258.1 | ticks=2761 return=283.000\n",
      "[STA] agent_hz=  258.2 | ticks=2904 return=297.000\n",
      "[STA] agent_hz=  258.3 | ticks=3049 return=311.000\n",
      "[STA] agent_hz=  258.4 | ticks=3192 return=327.000\n",
      "[STA] agent_hz=  258.7 | ticks=3334 return=337.000\n",
      "[STA] agent_hz=  259.0 | ticks=3476 return=356.000\n",
      "[STA] agent_hz=  259.1 | ticks=3619 return=367.000\n",
      "[STA] agent_hz=  259.2 | ticks=3761 return=386.000\n",
      "[STA] agent_hz=  259.2 | ticks=3907 return=397.000\n",
      "[STA] agent_hz=  259.1 | ticks=4053 return=416.000\n",
      "[STA] agent_hz=  258.9 | ticks=4201 return=427.000\n",
      "[STA] agent_hz=  258.7 | ticks=4348 return=446.000\n",
      "[STA] agent_hz=  258.8 | ticks=4492 return=457.000\n",
      "[STA] agent_hz=  258.7 | ticks=4639 return=476.000\n",
      "[STA] agent_hz=  258.8 | ticks=4782 return=487.000\n",
      "[STA] agent_hz=  259.0 | ticks=4924 return=506.000\n",
      "[STA] agent_hz=  259.0 | ticks=5067 return=516.000\n",
      "[STA] agent_hz=  259.2 | ticks=5209 return=536.000\n",
      "[STA] agent_hz=  259.2 | ticks=5353 return=546.000\n",
      "[STA] agent_hz=  259.3 | ticks=5496 return=566.000\n",
      "[STA] agent_hz=  259.5 | ticks=5636 return=575.000\n",
      "[STA] agent_hz=  259.6 | ticks=5778 return=594.000\n",
      "[STA] agent_hz=  259.6 | ticks=5923 return=604.000\n",
      "[STA] agent_hz=  259.0 | ticks=6081 return=626.000\n",
      "[STA] agent_hz=  258.7 | ticks=6234 return=636.000\n",
      "[STA] agent_hz=  258.7 | ticks=6378 return=656.000\n",
      "[STA] agent_hz=  258.7 | ticks=6523 return=666.000\n",
      "[STA] agent_hz=  258.7 | ticks=6668 return=686.000\n",
      "[STA] agent_hz=  258.8 | ticks=6811 return=696.000\n",
      "[STA] agent_hz=  258.9 | ticks=6954 return=716.000\n",
      "[STA] agent_hz=  258.8 | ticks=7100 return=725.000\n",
      "[STA] agent_hz=  258.9 | ticks=7242 return=745.000\n",
      "[STA] agent_hz=  258.7 | ticks=7392 return=755.000\n",
      "[STA] agent_hz=  258.6 | ticks=7541 return=776.000\n",
      "[STA] agent_hz=  258.6 | ticks=7685 return=785.000\n",
      "[STA] agent_hz=  258.3 | ticks=7838 return=806.000\n",
      "[STA] agent_hz=  258.4 | ticks=7982 return=816.000\n",
      "[STA] agent_hz=  258.5 | ticks=8124 return=836.000\n",
      "[STA] agent_hz=  258.5 | ticks=8268 return=845.000\n",
      "[STA] agent_hz=  258.5 | ticks=8413 return=866.000\n",
      "[STA] agent_hz=  258.5 | ticks=8560 return=875.000\n",
      "[STA] agent_hz=  258.5 | ticks=8704 return=896.000\n",
      "[STA] agent_hz=  258.5 | ticks=8850 return=905.000\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "# realtime_freeway.py\n",
    "# --------------------------------------------------------------------------------------\n",
    "# Real-time wrapper for pgx MinAtar Freeway + simple deployment loop for your PPO policy\n",
    "# No rtgym, no external framework — just a background thread ticking the env at fixed Hz.\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import pgx\n",
    "\n",
    "\n",
    "# realtime_freeway_sta.py\n",
    "# --------------------------------------------------------------------------------------\n",
    "# Real-time wrapper for pgx MinAtar Freeway + STA (Sense->Think->Act) deployment loop.\n",
    "# Env ticks in a background thread at high rate (default 850 Hz).\n",
    "# The agent runs at maximum speed: get_latest() -> forward pass -> send_action().\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import pgx\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Actor-Critic (as before)\n",
    "# =========================\n",
    "\n",
    "def pool_out_dim(n: int, window: int = 2, stride: int = 2, padding: str = \"VALID\") -> int:\n",
    "    if padding.upper() == \"VALID\":\n",
    "        return (n - window) // stride + 1\n",
    "    return int(np.ceil(n / stride))\n",
    "\n",
    "class ActorCritic(nnx.Module):\n",
    "    def __init__(self, num_actions: int, obs_shape, activation: str = \"tanh\", *, rngs: nnx.Rngs):\n",
    "        assert activation in [\"relu\", \"tanh\"]\n",
    "        self.num_actions = num_actions\n",
    "        self.activation = activation\n",
    "\n",
    "        H, W, C = obs_shape  # NHWC expected by flax.nnx.Conv\n",
    "        self.conv = nnx.Conv(in_features=C, out_features=32, kernel_size=(2, 2), rngs=rngs)\n",
    "        self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2), padding=\"VALID\")\n",
    "\n",
    "        H2 = pool_out_dim(H, 2, 2, \"VALID\")\n",
    "        W2 = pool_out_dim(W, 2, 2, \"VALID\")\n",
    "        flatten_dim = H2 * W2 * 32\n",
    "\n",
    "        self.fc = nnx.Linear(flatten_dim, 64, rngs=rngs)\n",
    "\n",
    "        self.actor_h1 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.actor_h2 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.actor_out = nnx.Linear(64, num_actions, rngs=rngs)\n",
    "\n",
    "        self.critic_h1 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.critic_h2 = nnx.Linear(64, 64, rngs=rngs)\n",
    "        self.critic_out = nnx.Linear(64, 1, rngs=rngs)\n",
    "\n",
    "    def _act(self, x):\n",
    "        return nnx.relu(x) if self.activation == \"relu\" else nnx.tanh(x)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.astype(jnp.float32)\n",
    "        x = self.conv(x)\n",
    "        x = nnx.relu(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nnx.relu(self.fc(x))\n",
    "\n",
    "        a = self._act(self.actor_h1(x))\n",
    "        a = self._act(self.actor_h2(a))\n",
    "        logits = self.actor_out(a)\n",
    "\n",
    "        v = self._act(self.critic_h1(x))\n",
    "        v = self._act(self.critic_h2(v))\n",
    "        value = self.critic_out(v)\n",
    "        return logits, jnp.squeeze(value, axis=-1)\n",
    "\n",
    "class Categorical:\n",
    "    def __init__(self, logits): self.logits = logits\n",
    "    def sample(self, seed): return jax.random.categorical(seed, self.logits)\n",
    "    def greedy(self): return jnp.argmax(self.logits, axis=-1)\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 2) Real-time wrapper around pgx Freeway env\n",
    "# ===========================================\n",
    "\n",
    "class RealTimeFreeway:\n",
    "    \"\"\"\n",
    "    Run pgx 'minatar-freeway' in a background thread at fixed Hertz.\n",
    "    - On each tick, apply the action at the head of a FIFO (for fixed delay).\n",
    "    - Keep latest (obs, aggregated reward since last read, done) as a snapshot.\n",
    "    - 'send_action' is non-blocking; action will take effect after `act_delay_ticks`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        tick_hz: float = 20.0,              # internal simulation frequency (wall-clock)\n",
    "        act_delay_ticks: int = 0,           # fixed action delay (in ticks)\n",
    "        sticky_action_prob: float = 0.0,    # often 0 for deployment\n",
    "        seed: int = 0,\n",
    "        use_minimal_action_set: bool = True,\n",
    "        env='minatar-freeway'\n",
    "        \n",
    "    ):\n",
    "        assert tick_hz > 0\n",
    "        assert act_delay_ticks >= 0\n",
    "        self.tick_hz = float(tick_hz)\n",
    "        self.dt = 1.0 / self.tick_hz\n",
    "        self.delay = int(act_delay_ticks)\n",
    "\n",
    "        # Build env\n",
    "        self.env = pgx.make(env)\n",
    "        # Configure behavior\n",
    "        self.env.use_minimal_action_set = bool(use_minimal_action_set)\n",
    "        self.env.sticky_action_prob = float(sticky_action_prob)\n",
    "\n",
    "        self.num_actions = self.env.num_actions  # should be 3 with minimal set\n",
    "        self.obs_shape = self.env.observation_shape  # (10,10,7)\n",
    "\n",
    "        # PRNG\n",
    "        self.key = jax.random.PRNGKey(seed)\n",
    "\n",
    "        # JIT step for performance and stable timing\n",
    "        self._step_jit = jax.jit(self.env.step)\n",
    "\n",
    "        # State & shared snapshot\n",
    "        self.state = None\n",
    "        self._lock = threading.Lock()\n",
    "        self._obs_latest = None            # np.float32 [10,10,7]\n",
    "        self._rew_accum = 0.0\n",
    "        self._done = True                  # not running until reset\n",
    "        self._episode_ticks = 0\n",
    "\n",
    "        # Action handling (default to NOOP=0 in minimal set)\n",
    "        self.default_action = 0\n",
    "        self.current_action = self.default_action\n",
    "        self._fifo = deque([self.default_action]*(self.delay+1), maxlen=self.delay+1)\n",
    "\n",
    "        # Loop\n",
    "        self._running = False\n",
    "        self._thread: Optional[threading.Thread] = None\n",
    "        self._thread_exc: Optional[BaseException] = None\n",
    "\n",
    "        # Warmup compiled function shapes with a dummy init->step\n",
    "        self._warmup_compilation()\n",
    "\n",
    "    # ------------- Public API -------------\n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment and (re)start real-time ticking.\"\"\"\n",
    "        self.key, k = jax.random.split(self.key)\n",
    "        self.state = self.env.init(k)\n",
    "\n",
    "        # One no-op step so 'step' is hot and any step-time randomness is stabilized\n",
    "        self.key, k = jax.random.split(self.key)\n",
    "        self.state = self._step_jit(self.state, jnp.int32(self.default_action), k)\n",
    "\n",
    "        with self._lock:\n",
    "            self._obs_latest = np.asarray(self.state.observation, dtype=np.float32)\n",
    "            self._rew_accum = float(self.state.rewards[0])\n",
    "            self._done = bool(self.state.terminated)\n",
    "            self.current_action = self.default_action\n",
    "            self._fifo.clear()\n",
    "            for _ in range(self.delay+1):\n",
    "                self._fifo.append(self.default_action)\n",
    "            self._episode_ticks = 0\n",
    "\n",
    "        self._start_loop()\n",
    "        # Return initial observation (copy)\n",
    "        return self._obs_latest.copy()\n",
    "\n",
    "    def send_action(self, action: int):\n",
    "        \"\"\"Publish the newest action (non-blocking).\"\"\"\n",
    "        a = int(action)\n",
    "        if not (0 <= a < self.num_actions):\n",
    "            raise ValueError(f\"Action {a} out of range [0, {self.num_actions-1}]\")\n",
    "        with self._lock:\n",
    "            self.current_action = a\n",
    "\n",
    "    def get_latest(self) -> Tuple[np.ndarray, float, bool, dict]:\n",
    "        \"\"\"\n",
    "        Non-blocking fetch of the latest snapshot.\n",
    "        Returns:\n",
    "          obs: np.float32[10,10,7]  latest observation\n",
    "          rew: float                reward accumulated since last get_latest()\n",
    "          done: bool\n",
    "          info: dict                {\"episode_ticks\": int}\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            obs = self._obs_latest.copy()\n",
    "            rew = float(self._rew_accum)\n",
    "            self._rew_accum = 0.0\n",
    "            done = bool(self._done)\n",
    "            info = {\"episode_ticks\": self._episode_ticks}\n",
    "        # If the thread died with an exception, surface it now:\n",
    "        if self._thread_exc is not None:\n",
    "            exc = self._thread_exc\n",
    "            self._thread_exc = None\n",
    "            raise exc\n",
    "        return obs, rew, done, info\n",
    "\n",
    "    def close(self):\n",
    "        self._stop_loop(join=True)\n",
    "\n",
    "    # ------------- Internals -------------\n",
    "    def _warmup_compilation(self):\n",
    "        # compile a minimal step ahead of time (no running loop)\n",
    "        key = jax.random.PRNGKey(12345)\n",
    "        s = self.env.init(key)\n",
    "        key, sub = jax.random.split(key)\n",
    "        _ = self._step_jit(s, jnp.int32(self.default_action), sub)\n",
    "\n",
    "    def _start_loop(self):\n",
    "        self._stop_loop(join=False)  # stop any previous loop\n",
    "        self._running = True\n",
    "        self._thread_exc = None\n",
    "        self._thread = threading.Thread(target=self._loop, daemon=True)\n",
    "        self._thread.start()\n",
    "\n",
    "    def _stop_loop(self, join: bool):\n",
    "        if self._thread and self._thread.is_alive():\n",
    "            self._running = False\n",
    "            if join:\n",
    "                self._thread.join(timeout=2.0)\n",
    "        self._thread = None\n",
    "\n",
    "    def _loop(self):\n",
    "        try:\n",
    "            next_t = time.perf_counter()\n",
    "            while self._running:\n",
    "                now = time.perf_counter()\n",
    "                if now < next_t:\n",
    "                    time.sleep(next_t - now)\n",
    "                next_t += self.dt\n",
    "\n",
    "                # Shift FIFO (delayed MDP)\n",
    "                with self._lock:\n",
    "                    self._fifo.popleft()\n",
    "                    self._fifo.append(self.current_action)\n",
    "                    act_to_apply = self._fifo[0]\n",
    "\n",
    "                # Step env\n",
    "                self.key, k = jax.random.split(self.key)\n",
    "                self.state = self._step_jit(self.state, jnp.int32(act_to_apply), k)\n",
    "\n",
    "                # Update snapshot\n",
    "                with self._lock:\n",
    "                    self._obs_latest = np.asarray(self.state.observation, dtype=np.float32)\n",
    "                    self._rew_accum += float(self.state.rewards[0])\n",
    "                    self._done = bool(self.state.terminated)\n",
    "                    self._episode_ticks += 1\n",
    "\n",
    "                # End-of-episode: stop ticking; user code should call reset()\n",
    "                if self._done:\n",
    "                    self._running = False\n",
    "                    break\n",
    "        except BaseException as e:\n",
    "            # stash exception to raise on next get_latest()\n",
    "            self._thread_exc = e\n",
    "            self._running = False\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3) STA deployment (Sense -> Think -> Act)\n",
    "# ============================================\n",
    "\n",
    "def load_actor_critic(ckpt_path: str, rng) -> ActorCritic:\n",
    "    # MinAtar Freeway with minimal action set: 3 actions; obs=(10,10,7)\n",
    "    num_actions = 3\n",
    "    obs_shape = (10, 10, 7)\n",
    "    model = ActorCritic(num_actions, obs_shape=obs_shape, activation=\"tanh\", rngs=nnx.Rngs(rng))\n",
    "    with open(ckpt_path, \"rb\") as f:\n",
    "        param_state = pickle.load(f)\n",
    "    nnx.update(model, param_state)\n",
    "    return model\n",
    "\n",
    "def deploy_realtime(\n",
    "    ckpt_path: str,\n",
    "    tick_hz: float = 850.0,\n",
    "    agent_hz: float = 0.0,     # unused\n",
    "    act_delay_ticks: int = 0,\n",
    "    sticky_action_prob: float = 0.0,\n",
    "    env='minatar-freeway',\n",
    "    num_episodes: int = 5,     # <-- NEW: run exactly 5 episodes\n",
    "):\n",
    "    rt = RealTimeFreeway(\n",
    "        tick_hz=tick_hz,\n",
    "        act_delay_ticks=act_delay_ticks,\n",
    "        sticky_action_prob=sticky_action_prob,\n",
    "        seed=0,\n",
    "        env=env,\n",
    "        use_minimal_action_set=True,\n",
    "    )\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    model = load_actor_critic(ckpt_path, init_rng)\n",
    "\n",
    "    # Episode/bookkeeping\n",
    "    obs = rt.reset()\n",
    "    ep_return, ep_steps, total_steps = 0.0, 0, 0\n",
    "    t0 = time.perf_counter()\n",
    "    ep_count = 0\n",
    "    returns = []\n",
    "\n",
    "    try:\n",
    "        while ep_count < num_episodes:\n",
    "            # --- Sense ---\n",
    "            obs, rew, done, info = rt.get_latest()\n",
    "            ep_return += rew; ep_steps += 1; total_steps += 1\n",
    "\n",
    "            # --- Think ---\n",
    "            o = obs[None, ...]\n",
    "            logits, _ = model(o)\n",
    "            action = int(Categorical(logits).greedy()[0])\n",
    "\n",
    "            # --- Act ---\n",
    "            rt.send_action(action)\n",
    "\n",
    "            # Throughput log\n",
    "            if total_steps % 500 == 0:\n",
    "                elapsed = time.perf_counter() - t0\n",
    "                agent_hz_eff = total_steps / max(elapsed, 1e-9)\n",
    "                print(f\"[STA] agent_hz={agent_hz_eff:7.1f} | ticks={info.get('episode_ticks')} return={ep_return:.3f}\")\n",
    "\n",
    "            if done:\n",
    "                print(f\"[Episode {ep_count+1} done] return={ep_return:.3f} | agent_steps={ep_steps} | ticks={info.get('episode_ticks')}\")\n",
    "                returns.append(ep_return)\n",
    "                ep_count += 1\n",
    "                if ep_count < num_episodes:\n",
    "                    obs = rt.reset()\n",
    "                    ep_return, ep_steps = 0.0, 0\n",
    "\n",
    "        # After exactly 5 episodes\n",
    "        avg_return = float(np.mean(returns)) if returns else 0.0\n",
    "        print(f\"[Summary] episodes={ep_count} | avg_return_over_{ep_count}={avg_return:.3f}\")\n",
    "        return avg_return\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user.\")\n",
    "    finally:\n",
    "        rt.close()\n",
    "\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# 4) Run from command line\n",
    "# ===========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ENV_NAME='minatar-breakout'\n",
    "    # --- EDIT THIS PATH ---\n",
    "    CKPT_PATH = f\"/home/ubuntu/tensorflow_test/control/real-timeRL/realtime-atari-jax/examples/minatar-ppo/{ENV_NAME}-seed=0-notebook.ckpt\"\n",
    "\n",
    "    # STA at high tick rate (850 Hz)\n",
    "    deploy_realtime(\n",
    "        ckpt_path=CKPT_PATH,\n",
    "        tick_hz=75.0,          # env ticks ~ every 1.176 ms\n",
    "        agent_hz=0.0,           # ignored in STA mode\n",
    "        act_delay_ticks=0,\n",
    "        sticky_action_prob=0.0,\n",
    "        env= ENV_NAME,\n",
    "        num_episodes=10\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeway\n",
    "\n",
    "#agent hz ~ 177hz\n",
    "\n",
    "#optimal: 71\n",
    "# env hz at 50ticks avg: 71.00\n",
    "\n",
    "# env hz at 150ticks avg: 64.000\n",
    "\n",
    "# env hz at 250ticks avg: 52.800\n",
    "\n",
    "# env hz at 450ticks avg: 41.00\n",
    "\n",
    "# env hz at 650ticks avg: 40.200\n",
    "\n",
    "# env hz at 850ticks avg: 38.700\n",
    "\n",
    "\n",
    "# Breakout\n",
    "\n",
    "#agent hz ~ 235\n",
    "\n",
    "#optimal: 275\n",
    "# env hz at 50ticks avg: 250.75999450683594\n",
    "\n",
    "# env hz at 150ticks avg: 21.000\n",
    "\n",
    "# env hz at 250ticks avg: 5.3\n",
    "\n",
    "# env hz at 450ticks avg: 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37f2c96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Data\n",
    "# ---------------------------\n",
    "data = {\n",
    "    \"env_hz\": [50, 150, 250, 450, 650, 850],\n",
    "    \"Freeway\": [71.0, 64.0, 52.8, 41.0, 40.2, 38.7],\n",
    "    \"Breakout\": [650.76, 21.0, 5.3, 1.5, None, None],\n",
    "}\n",
    "\n",
    "# Optimal rewards\n",
    "optimal_rewards = {\"Freeway\": 71.0, \"Breakout\": 685.0}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ---------------------------\n",
    "# Minimal flat design style\n",
    "# ---------------------------\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "\n",
    "# Flat color palette - using a sophisticated blue-grey\n",
    "primary_color = '#4A90E2'  # Soft blue\n",
    "optimal_color = '#95A5A6'  # Light grey\n",
    "text_color = '#2C3E50'     # Dark blue-grey\n",
    "grid_color = '#ECF0F1'     # Very light grey\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), facecolor='white')\n",
    "\n",
    "# ---------------------------\n",
    "# Freeway subplot\n",
    "# ---------------------------\n",
    "env = \"Freeway\"\n",
    "freeway_data = df[['env_hz', env]].dropna()\n",
    "\n",
    "axes[0].bar(\n",
    "    freeway_data['env_hz'], \n",
    "    freeway_data[env],\n",
    "    width=80,\n",
    "    color=primary_color,\n",
    "    edgecolor='none',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "axes[0].axhline(\n",
    "    optimal_rewards[env], \n",
    "    color=optimal_color, \n",
    "    linestyle='--', \n",
    "    linewidth=2,\n",
    "    alpha=0.7,\n",
    "    zorder=0\n",
    ")\n",
    "\n",
    "axes[0].set_title(\n",
    "    f\"{env}\\nAgent ~177 Hz\", \n",
    "    fontsize=16, \n",
    "    color=text_color,\n",
    "    pad=20,\n",
    "    fontweight='500'\n",
    ")\n",
    "axes[0].set_xlabel(\"Environment tick rate (Hz)\", fontsize=13, color=text_color)\n",
    "axes[0].set_ylabel(\"Average Reward\", fontsize=13, color=text_color)\n",
    "axes[0].set_ylim(30, 80)\n",
    "\n",
    "# Styling\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['left'].set_color('#BDC3C7')\n",
    "axes[0].spines['bottom'].set_color('#BDC3C7')\n",
    "axes[0].tick_params(colors=text_color, which='both', length=0)\n",
    "axes[0].grid(axis='y', alpha=0.3, color=grid_color, linewidth=1)\n",
    "axes[0].set_axisbelow(True)\n",
    "\n",
    "axes[0].text(\n",
    "    850, \n",
    "    optimal_rewards[env] + 1.5, \n",
    "    \"Optimal\", \n",
    "    fontsize=11, \n",
    "    color=optimal_color,\n",
    "    ha='right',\n",
    "    style='italic'\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Breakout subplot\n",
    "# ---------------------------\n",
    "env = \"Breakout\"\n",
    "breakout_data = df[['env_hz', env]].dropna()\n",
    "\n",
    "axes[1].bar(\n",
    "    breakout_data['env_hz'], \n",
    "    breakout_data[env],\n",
    "    width=80,\n",
    "    color=primary_color,\n",
    "    edgecolor='none',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "axes[1].axhline(\n",
    "    optimal_rewards[env], \n",
    "    color=optimal_color, \n",
    "    linestyle='--', \n",
    "    linewidth=2,\n",
    "    alpha=0.7,\n",
    "    zorder=0\n",
    ")\n",
    "\n",
    "axes[1].set_title(\n",
    "    f\"{env}\\nAgent ~235 Hz\", \n",
    "    fontsize=16, \n",
    "    color=text_color,\n",
    "    pad=20,\n",
    "    fontweight='500'\n",
    ")\n",
    "axes[1].set_xlabel(\"Environment tick rate (Hz)\", fontsize=13, color=text_color)\n",
    "axes[1].set_ylabel(\"Average Reward\", fontsize=13, color=text_color)\n",
    "axes[1].set_ylim(0, 750)\n",
    "\n",
    "# Styling\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['left'].set_color('#BDC3C7')\n",
    "axes[1].spines['bottom'].set_color('#BDC3C7')\n",
    "axes[1].tick_params(colors=text_color, which='both', length=0)\n",
    "axes[1].grid(axis='y', alpha=0.3, color=grid_color, linewidth=1)\n",
    "axes[1].set_axisbelow(True)\n",
    "\n",
    "axes[1].text(\n",
    "    450, \n",
    "    optimal_rewards[env] + 25, \n",
    "    \"Optimal\", \n",
    "    fontsize=11, \n",
    "    color=optimal_color,\n",
    "    ha='right',\n",
    "    style='italic'\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Global title + layout\n",
    "# ---------------------------\n",
    "fig.suptitle(\n",
    "    \"Effect of Environment Tick Rate on PPO-Trained Policy\", \n",
    "    fontsize=18, \n",
    "    color=text_color,\n",
    "    y=0.98,\n",
    "    fontweight='500'\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig('minimal_plot.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
